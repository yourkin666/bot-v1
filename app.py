#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€èŠå¤©æœºå™¨äºº Web åº”ç”¨
é›†æˆSiliconFlowæ–‡æœ¬å¤„ç†å’ŒGroqå›¾ç‰‡å¤„ç†çš„Flaskåç«¯æœåŠ¡
"""

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import requests
import json
import base64
import os
import tempfile
import io
from typing import List, Dict, Optional
import logging
from dotenv import load_dotenv
from database import ChatDatabase
from datetime import datetime, timedelta
import re

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# APIé…ç½®
SILICONFLOW_API_KEY = os.environ.get("SILICONFLOW_API_KEY", "sk-icupqsqwcgsfnqbwpcgfertxbdlkksapxtacxlupjzanguyv")
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"
GROQ_BASE_URL = "https://api.groq.com/openai/v1"
OPENAI_BASE_URL = "https://api.openai.com/v1"

# å¯ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = [
    {
        "id": "deepseek-ai/DeepSeek-V2.5",
        "name": "DeepSeek-V2.5 (æ–‡æœ¬)",
        "provider": "siliconflow",
        "default": True,
        "supports_image": False,
        "type": "text"
    },
    {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "name": "Qwen2.5-7B (æ–‡æœ¬)",
        "provider": "siliconflow",
        "default": False,
        "supports_image": False,
        "type": "text"
    },
    {
        "id": "meta-llama/llama-4-scout-17b-16e-instruct",
        "name": "Llama 4 Scout (å¤šæ¨¡æ€)",
        "provider": "groq",
        "default": False,
        "supports_image": True,
        "type": "multimodal"
    },
    {
        "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
        "name": "Llama 4 Maverick (å¤šæ¨¡æ€)",
        "provider": "groq",
        "default": False,
        "supports_image": True,
        "type": "multimodal"
    }
]

# ç¯å¢ƒå˜é‡è·å–
BOCHA_API_KEY = os.environ.get('BOCHA_API_KEY', 'sk-38eaefcfac2d4c39a50c3cd686022e2d')

class MultiModalChatBotService:
    def __init__(self, siliconflow_api_key: str, groq_api_key: str, openai_api_key: str = None):
        self.siliconflow_api_key = siliconflow_api_key
        self.groq_api_key = groq_api_key
        self.openai_api_key = openai_api_key
        self.siliconflow_base_url = SILICONFLOW_BASE_URL.rstrip('/') + '/chat/completions'
        self.groq_base_url = GROQ_BASE_URL.rstrip('/') + '/chat/completions'
        self.openai_transcription_url = OPENAI_BASE_URL.rstrip('/') + '/audio/transcriptions'
        
    def get_response(self, messages: List[Dict], model: str = "deepseek-ai/DeepSeek-V2.5", system_prompt: str = None, temperature: float = 0.7, tools: List[Dict] = None) -> Dict:
        """è·å–AIå›å¤ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æœåŠ¡æä¾›å•†ï¼Œæ”¯æŒFunction Calling"""
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šåª’ä½“å†…å®¹
        has_image = self._has_image_content(messages)
        has_multimedia = self._has_multimedia_content(messages)
        model_info = self._get_model_info(model)
        
        if not model_info:
            return {
                "success": False,
                "error": f"æœªçŸ¥æ¨¡å‹: {model}"
            }
        
        # å¦‚æœæœ‰å›¾ç‰‡ä½†æ¨¡å‹ä¸æ”¯æŒï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æ”¯æŒå›¾ç‰‡çš„æ¨¡å‹
        if has_image and not model_info["supports_image"]:
            # è‡ªåŠ¨é€‰æ‹©Groqçš„å¤šæ¨¡æ€æ¨¡å‹
            model = "meta-llama/llama-4-scout-17b-16e-instruct"
            model_info = self._get_model_info(model)
            logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤šæ¨¡æ€æ¨¡å‹: {model}")
        # å¦‚æœæœ‰éŸ³é¢‘/è§†é¢‘ä½†æ²¡æœ‰å›¾ç‰‡ï¼Œä¹Ÿåˆ‡æ¢åˆ°æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹ï¼ˆç”¨äºæ–‡æœ¬åˆ†æï¼‰
        elif has_multimedia and not has_image and not model_info["supports_image"]:
            model = "meta-llama/llama-4-scout-17b-16e-instruct"
            model_info = self._get_model_info(model)
            logger.info(f"æ£€æµ‹åˆ°å¤šåª’ä½“å†…å®¹ï¼Œåˆ‡æ¢åˆ°å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†æ: {model}")
        
        # æ ¹æ®æ¨¡å‹æä¾›å•†é€‰æ‹©API
        if model_info["provider"] == "groq":
            return self._get_groq_response(messages, model, system_prompt, temperature, tools)
        else:
            return self._get_siliconflow_response(messages, model, system_prompt, temperature, tools)
    
    def _has_image_content(self, messages: List[Dict]) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        for msg in messages:
            if msg.get('image'):
                return True
        return False
    
    def _has_multimedia_content(self, messages: List[Dict]) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å¤šåª’ä½“å†…å®¹ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ï¼‰"""
        for msg in messages:
            if msg.get('image') or msg.get('audio') or msg.get('video'):
                return True
        return False
    
    def _get_model_info(self, model: str) -> Optional[Dict]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        for m in AVAILABLE_MODELS:
            if m["id"] == model:
                return m
        return None
    
    def _get_siliconflow_response(self, messages: List[Dict], model: str, system_prompt: str = None, temperature: float = 0.7, tools: List[Dict] = None) -> Dict:
        """ä½¿ç”¨SiliconFlow APIè·å–å›å¤"""
        if not self.siliconflow_api_key:
            return {
                "success": False,
                "error": "SiliconFlow APIå¯†é’¥æœªé…ç½®"
            }
        
        headers = {
            "Authorization": f"Bearer {self.siliconflow_api_key}",
            "Content-Type": "application/json"
        }
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼ˆåªå¤„ç†æ–‡æœ¬ï¼‰
        api_messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if system_prompt:
            api_messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        for msg in messages:
            if msg['role'] == 'user':
                text_content = msg.get('text', '')
                
                # æ·»åŠ å¤šåª’ä½“å†…å®¹çš„æç¤º
                if msg.get('image'):
                    text_content += " [æ³¨ï¼šæ£€æµ‹åˆ°å›¾ç‰‡ï¼Œä½†å½“å‰æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡å¤„ç†]"
                # éŸ³é¢‘å’Œè§†é¢‘å†…å®¹æç¤ºå·²åœ¨é¢„å¤„ç†ä¸­åŠ å…¥ï¼Œè¿™é‡Œä¸é‡å¤æ·»åŠ 
                
                api_messages.append({
                    "role": "user",
                    "content": text_content if text_content.strip() else "è¯·æä¾›å¸®åŠ©ã€‚"
                })
            else:
                api_messages.append({
                    "role": msg['role'],
                    "content": msg.get('text', '')
                })
        
        data = {
            "model": model,
            "messages": api_messages,
            "stream": False,
            "max_tokens": 2000,
            "temperature": temperature
        }
        
        # æ·»åŠ å·¥å…·æ”¯æŒ
        if tools:
            data["tools"] = tools
            data["tool_choice"] = "auto"
        
        logger.info(f"ä½¿ç”¨SiliconFlow APIï¼Œæ¨¡å‹: {model}")
        
        # å°è¯•å¤šæ¬¡è°ƒç”¨ï¼Œå¤„ç†ç½‘ç»œè¶…æ—¶é—®é¢˜
        max_retries = 2
        timeout_seconds = 60  # å¢åŠ è¶…æ—¶æ—¶é—´
        
        for attempt in range(max_retries):
            try:
                logger.info(f"SiliconFlow APIè°ƒç”¨å°è¯• {attempt + 1}/{max_retries}")
                response = requests.post(
                    self.siliconflow_base_url, 
                    headers=headers, 
                    json=data, 
                    timeout=timeout_seconds
                )
                response.raise_for_status()
                
                result = response.json()
                message = result['choices'][0]['message']
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if message.get('tool_calls'):
                    logger.info(f"SiliconFlow APIè°ƒç”¨æˆåŠŸ - æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
                    return {
                        "success": True,
                        "message": message,
                        "tool_calls": message['tool_calls'],
                        "provider": "siliconflow",
                        "model": model,
                        "requires_tool_execution": True
                    }
                else:
                    ai_response = message.get('content', '')
                    logger.info(f"SiliconFlow APIè°ƒç”¨æˆåŠŸ")
                    return {
                        "success": True,
                        "response": ai_response,
                        "provider": "siliconflow",
                        "model": model
                    }
                
            except requests.exceptions.Timeout as e:
                logger.warning(f"SiliconFlow APIè¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Groqä½œä¸ºå¤‡ç”¨
                    logger.info("SiliconFlow APIå¤šæ¬¡è¶…æ—¶ï¼Œå°è¯•ä½¿ç”¨Groqä½œä¸ºå¤‡ç”¨")
                    return self._get_groq_fallback_response(messages, system_prompt, temperature)
                continue
                
            except requests.exceptions.ConnectionError as e:
                logger.warning(f"SiliconFlow APIè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    logger.info("SiliconFlow APIè¿æ¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Groqä½œä¸ºå¤‡ç”¨")
                    return self._get_groq_fallback_response(messages, system_prompt, temperature)
                continue
                
            except Exception as e:
                logger.error(f"SiliconFlow APIé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    return {
                        "success": False,
                        "error": f"SiliconFlow APIé”™è¯¯: {str(e)}"
                    }
                continue
        
        return {
            "success": False,
            "error": "SiliconFlow APIè°ƒç”¨å¤±è´¥"
        }
    
    def _get_groq_fallback_response(self, messages: List[Dict], system_prompt: str = None, temperature: float = 0.7) -> Dict:
        """å½“SiliconFlowå¤±è´¥æ—¶ä½¿ç”¨Groqä½œä¸ºå¤‡ç”¨"""
        logger.info("ä½¿ç”¨Groqä½œä¸ºSiliconFlowçš„å¤‡ç”¨æœåŠ¡")
        fallback_model = "meta-llama/llama-4-scout-17b-16e-instruct"
        return self._get_groq_response(messages, fallback_model, system_prompt, temperature)
    
    def _get_groq_response(self, messages: List[Dict], model: str, system_prompt: str = None, temperature: float = 0.7, tools: List[Dict] = None) -> Dict:
        """ä½¿ç”¨Groq APIè·å–å›å¤"""
        if not self.groq_api_key:
            return {
                "success": False,
                "error": "Groq APIå¯†é’¥æœªé…ç½®"
            }
        
        headers = {
            "Authorization": f"Bearer {self.groq_api_key}",
            "Content-Type": "application/json"
        }
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        api_messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if system_prompt:
            api_messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        for msg in messages:
            if msg['role'] == 'user':
                content = []
                
                # æ·»åŠ æ–‡æœ¬å†…å®¹
                text_parts = []
                if msg.get('text'):
                    text_parts.append(msg['text'])
                
                # éŸ³é¢‘å’Œè§†é¢‘æ•°æ®å·²åœ¨é¢„å¤„ç†ä¸­ç§»é™¤ï¼Œåªå¤„ç†æ–‡æœ¬å†…å®¹
                
                # åˆå¹¶æ–‡æœ¬å†…å®¹
                if text_parts:
                    content.append({
                        "type": "text",
                        "text": " ".join(text_parts)
                    })
                
                # æ·»åŠ å›¾ç‰‡å†…å®¹ï¼ˆGroq APIæ”¯æŒå›¾ç‰‡ï¼‰
                if msg.get('image'):
                    image_data = msg['image']
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": image_data
                        }
                    })
                
                # å¯¹äºGroq APIï¼Œæ€»æ˜¯ä½¿ç”¨æ•°ç»„æ ¼å¼æ¥æ”¯æŒå¤šæ¨¡æ€
                # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œæä¾›é»˜è®¤æ–‡æœ¬
                if content:
                    api_messages.append({
                        "role": "user",
                        "content": content
                    })
                else:
                    # æ²¡æœ‰å†…å®¹ï¼Œä½¿ç”¨é»˜è®¤æç¤º
                    api_messages.append({
                        "role": "user",
                        "content": [{"type": "text", "text": "è¯·æä¾›å¸®åŠ©ã€‚"}]
                    })
            else:
                api_messages.append({
                    "role": msg['role'],
                    "content": msg.get('text', '')
                })
        
        data = {
            "model": model,
            "messages": api_messages,
            "temperature": temperature,
            "max_completion_tokens": 1024,
            "top_p": 1,
            "stream": False
        }
        
        # æ·»åŠ å·¥å…·æ”¯æŒ
        if tools:
            data["tools"] = tools
            data["tool_choice"] = "auto"
        
        logger.info(f"ä½¿ç”¨Groq APIï¼Œæ¨¡å‹: {model}")
        
        try:
            logger.info(f"è°ƒç”¨Groq APIï¼Œæ¨¡å‹: {model}")
            response = requests.post(self.groq_base_url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            message = result['choices'][0]['message']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if message.get('tool_calls'):
                logger.info(f"Groq APIè°ƒç”¨æˆåŠŸ - æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
                return {
                    "success": True,
                    "message": message,
                    "tool_calls": message['tool_calls'],
                    "provider": "groq",
                    "model": model,
                    "requires_tool_execution": True
                }
            else:
                ai_response = message.get('content', '')
                return {
                    "success": True,
                    "response": ai_response,
                    "provider": "groq",
                    "model": model
                }
            
        except Exception as e:
            logger.error(f"Groq APIé”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"Groq APIé”™è¯¯: {str(e)}"
            }
    
    def transcribe_audio(self, audio_data: str, language: str = "zh") -> Dict:
        """ä½¿ç”¨OpenAI Whisper APIå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—"""
        if not self.openai_api_key:
            return {
                "success": False,
                "error": "OpenAI APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½",
                "fallback_available": True,
                "fallback_message": "å»ºè®®ä½¿ç”¨æµè§ˆå™¨å†…ç½®çš„è¯­éŸ³è¯†åˆ«åŠŸèƒ½"
            }
        
        try:
            # è§£æbase64éŸ³é¢‘æ•°æ®
            if not audio_data.startswith('data:audio/'):
                return {
                    "success": False,
                    "error": "æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼"
                }
            
            # æå–base64å†…å®¹å’ŒMIMEç±»å‹
            header, base64_content = audio_data.split(',', 1)
            mime_type = header.split(':')[1].split(';')[0]
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            if 'webm' in mime_type:
                file_extension = 'webm'
            elif 'wav' in mime_type:
                file_extension = 'wav'
            elif 'mp3' in mime_type:
                file_extension = 'mp3'
            elif 'ogg' in mime_type:
                file_extension = 'ogg'
            else:
                file_extension = 'webm'  # é»˜è®¤
            
            # è§£ç base64æ•°æ®
            audio_bytes = base64.b64decode(base64_content)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=f'.{file_extension}', delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            try:
                # è°ƒç”¨OpenAI Whisper API
                headers = {
                    "Authorization": f"Bearer {self.openai_api_key}"
                }
                
                with open(temp_file_path, 'rb') as audio_file:
                    files = {
                        'file': (f'audio.{file_extension}', audio_file, mime_type),
                        'model': (None, 'whisper-1'),
                        'language': (None, language),
                        'response_format': (None, 'json')
                    }
                    
                    response = requests.post(
                        self.openai_transcription_url,
                        headers=headers,
                        files=files,
                        timeout=30
                    )
                    
                response.raise_for_status()
                result = response.json()
                
                transcribed_text = result.get('text', '').strip()
                
                return {
                    "success": True,
                    "text": transcribed_text,
                    "language": language,
                    "duration": result.get('duration'),
                    "model": "whisper-1"
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_file_path)
                except:
                    pass
                    
        except Exception as e:
            logger.error(f"è¯­éŸ³è½¬æ–‡å­—é”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}"
            }
    
    def transcribe_audio_fallback(self, audio_data: str, text: str = None) -> Dict:
        """å¤‡ç”¨çš„è¯­éŸ³è½¬æ–‡å­—æ–¹æ³•ï¼Œç›´æ¥æ¥æ”¶å·²è½¬å½•çš„æ–‡æœ¬"""
        if not text:
            return {
                "success": False,
                "error": "æ²¡æœ‰æä¾›è½¬å½•æ–‡æœ¬",
                "fallback_used": True
            }
        
        return {
            "success": True,
            "text": text.strip(),
            "language": "auto",
            "model": "browser-speech-api",
            "fallback_used": True
        }
    
    def transcribe_audio_with_groq(self, audio_data: str, language: str = "zh") -> Dict:
        """ä½¿ç”¨Groq Speech-to-Text APIå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—"""
        if not self.groq_api_key:
            return {
                "success": False,
                "error": "Groq APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨Groqè¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½"
            }
        
        try:
            # è§£æbase64éŸ³é¢‘æ•°æ®
            if not audio_data.startswith('data:audio/'):
                return {
                    "success": False,
                    "error": "æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼"
                }
            
            # æå–base64å†…å®¹å’ŒMIMEç±»å‹
            header, base64_content = audio_data.split(',', 1)
            mime_type = header.split(':')[1].split(';')[0]
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            if 'webm' in mime_type:
                file_extension = 'webm'
            elif 'wav' in mime_type:
                file_extension = 'wav'
            elif 'mp3' in mime_type:
                file_extension = 'mp3'
            elif 'ogg' in mime_type:
                file_extension = 'ogg'
            else:
                file_extension = 'webm'  # é»˜è®¤
            
            # è§£ç base64æ•°æ®
            audio_bytes = base64.b64decode(base64_content)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=f'.{file_extension}', delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            try:
                # è°ƒç”¨Groq Speech-to-Text API
                headers = {
                    "Authorization": f"Bearer {self.groq_api_key}"
                }
                
                with open(temp_file_path, 'rb') as audio_file:
                    files = {
                        'file': (f'audio.{file_extension}', audio_file, mime_type),
                        'model': (None, 'whisper-large-v3-turbo'),  # ä½¿ç”¨Groqçš„å¿«é€Ÿæ¨¡å‹
                        'language': (None, language if language != 'zh' else 'zh'),
                        'response_format': (None, 'json')
                    }
                    
                    response = requests.post(
                        'https://api.groq.com/openai/v1/audio/transcriptions',
                        headers=headers,
                        files=files,
                        timeout=30
                    )
                    
                response.raise_for_status()
                result = response.json()
                
                transcribed_text = result.get('text', '').strip()
                
                return {
                    "success": True,
                    "text": transcribed_text,
                    "language": language,
                    "duration": result.get('duration'),
                    "model": "groq-whisper-large-v3-turbo"
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_file_path)
                except:
                    pass
                    
        except Exception as e:
            logger.error(f"Groqè¯­éŸ³è½¬æ–‡å­—é”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"Groqè¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}"
            }
    
    def extract_video_frames(self, video_data: str, max_frames: int = 8) -> Dict:
        """ä»è§†é¢‘ä¸­æ™ºèƒ½æå–å…³é”®å¸§å’ŒéŸ³é¢‘ç”¨äºå®Œæ•´åˆ†æ"""
        try:
            # è§£æbase64è§†é¢‘æ•°æ®
            if not video_data.startswith('data:video/'):
                return {
                    "success": False,
                    "error": "æ— æ•ˆçš„è§†é¢‘æ•°æ®æ ¼å¼"
                }
            
            # æå–base64å†…å®¹
            header, base64_content = video_data.split(',', 1)
            mime_type = header.split(':')[1].split(';')[0]
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            if 'mp4' in mime_type:
                file_extension = 'mp4'
            elif 'webm' in mime_type:
                file_extension = 'webm'
            elif 'avi' in mime_type:
                file_extension = 'avi'
            else:
                file_extension = 'mp4'  # é»˜è®¤
            
            # è§£ç base64æ•°æ®
            video_bytes = base64.b64decode(base64_content)
            
            # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=f'.{file_extension}', delete=False) as temp_file:
                temp_file.write(video_bytes)
                temp_video_path = temp_file.name
            
            try:
                import cv2
                
                # æ‰“å¼€è§†é¢‘
                cap = cv2.VideoCapture(temp_video_path)
                if not cap.isOpened():
                    return {
                        "success": False,
                        "error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"
                    }
                
                # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                duration = total_frames / fps if fps > 0 else 0
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                
                frames = []
                frame_analysis = []
                
                # æ™ºèƒ½å¸§é€‰æ‹©ç­–ç•¥
                if total_frames > 0:
                    # 1. å¼€å§‹å¸§ (ç¬¬1ç§’)
                    start_frame = min(int(fps), total_frames - 1) if fps > 0 else 0
                    
                    # 2. ç»“æŸå¸§ (æœ€å1ç§’)
                    end_frame = max(total_frames - int(fps), 0) if fps > 0 else total_frames - 1
                    
                    # 3. ä¸­é—´å‡åŒ€åˆ†å¸ƒçš„å¸§
                    middle_frames = []
                    if total_frames > max_frames:
                        step = total_frames // (max_frames - 2)  # å‡å»å¼€å§‹å’Œç»“æŸå¸§
                        middle_frames = [i * step for i in range(1, max_frames - 1)]
                    else:
                        middle_frames = list(range(1, total_frames - 1))
                    
                    # 4. è¿åŠ¨æ£€æµ‹å¸§ï¼ˆæ¯25%çš„ä½ç½®é‡‡æ ·æ£€æµ‹ï¼‰
                    motion_sample_frames = [
                        int(total_frames * 0.25),
                        int(total_frames * 0.5),
                        int(total_frames * 0.75)
                    ]
                    
                    # åˆå¹¶æ‰€æœ‰å¸§ç´¢å¼•å¹¶å»é‡
                    all_frame_indices = list(set([start_frame] + middle_frames + [end_frame] + motion_sample_frames))
                    all_frame_indices = sorted([f for f in all_frame_indices if 0 <= f < total_frames])
                    
                    # é™åˆ¶å¸§æ•°
                    if len(all_frame_indices) > max_frames:
                        # ä¿ç•™å¼€å§‹ã€ç»“æŸå’Œå‡åŒ€åˆ†å¸ƒçš„å¸§
                        step = len(all_frame_indices) // max_frames
                        all_frame_indices = all_frame_indices[::step][:max_frames]
                
                # æå–å¸§å¹¶è¿›è¡ŒåŸºç¡€åˆ†æ
                prev_frame_gray = None
                for i, frame_idx in enumerate(all_frame_indices):
                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                    ret, frame = cap.read()
                    
                    if ret:
                        # è½¬æ¢ä¸ºbase64æ ¼å¼
                        _, buffer = cv2.imencode('.jpg', frame)
                        frame_base64 = base64.b64encode(buffer).decode('utf-8')
                        frame_data_url = f"data:image/jpeg;base64,{frame_base64}"
                        frames.append(frame_data_url)
                        
                        # è®¡ç®—æ—¶é—´æˆ³
                        timestamp = frame_idx / fps if fps > 0 else frame_idx
                        
                        # åŸºç¡€å¸§åˆ†æ
                        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                        
                        # è¿åŠ¨æ£€æµ‹
                        motion_score = 0
                        if prev_frame_gray is not None:
                            diff = cv2.absdiff(frame_gray, prev_frame_gray)
                            motion_score = cv2.sumElems(diff)[0] / (width * height)
                        
                        # äº®åº¦åˆ†æ
                        brightness = cv2.mean(frame_gray)[0]
                        
                        # è¾¹ç¼˜å¯†åº¦ï¼ˆåœºæ™¯å¤æ‚åº¦ï¼‰
                        edges = cv2.Canny(frame_gray, 50, 150)
                        edge_density = cv2.sumElems(edges)[0] / (width * height)
                        
                        frame_info = {
                            "index": frame_idx,
                            "timestamp": round(timestamp, 2),
                            "time_formatted": f"{int(timestamp//60):02d}:{int(timestamp%60):02d}",
                            "motion_score": round(motion_score, 2),
                            "brightness": round(brightness, 2),
                            "scene_complexity": round(edge_density, 2),
                            "position": "å¼€å§‹" if i == 0 else "ç»“æŸ" if i == len(all_frame_indices)-1 else f"ä¸­é—´{i}"
                        }
                        frame_analysis.append(frame_info)
                        prev_frame_gray = frame_gray
                
                cap.release()
                
                # å°è¯•æå–éŸ³é¢‘ä¿¡æ¯
                audio_info = self._extract_video_audio_info(temp_video_path)
                
                # ç”Ÿæˆè§†é¢‘åˆ†ææ‘˜è¦
                analysis_summary = self._generate_video_analysis_summary(
                    frame_analysis, duration, total_frames, fps, audio_info
                )
                
                return {
                    "success": True,
                    "frames": frames,
                    "frame_count": len(frames),
                    "total_frames": total_frames,
                    "duration": round(duration, 2),
                    "fps": round(fps, 2),
                    "resolution": f"{width}x{height}",
                    "frame_analysis": frame_analysis,
                    "audio_info": audio_info,
                    "analysis_summary": analysis_summary,
                    "video_stats": {
                        "avg_motion": round(sum(f["motion_score"] for f in frame_analysis) / len(frame_analysis), 2) if frame_analysis else 0,
                        "avg_brightness": round(sum(f["brightness"] for f in frame_analysis) / len(frame_analysis), 2) if frame_analysis else 0,
                        "scene_changes": len([f for f in frame_analysis if f["motion_score"] > 50])
                    }
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_video_path)
                except:
                    pass
                    
        except ImportError:
            logger.warning("OpenCVæœªå®‰è£…ï¼Œæ— æ³•æå–è§†é¢‘å¸§ã€‚è¯·è¿è¡Œ: pip install opencv-python")
            return {
                "success": False,
                "error": "è§†é¢‘å¤„ç†åŠŸèƒ½éœ€è¦å®‰è£… opencv-python åº“"
            }
        except Exception as e:
            logger.error(f"è§†é¢‘å¸§æå–é”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"è§†é¢‘å¸§æå–å¤±è´¥: {str(e)}"
            }
    
    def _extract_video_audio_info(self, video_path: str) -> Dict:
        """æå–è§†é¢‘ä¸­çš„éŸ³é¢‘ä¿¡æ¯"""
        try:
            import cv2
            
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦åŒ…å«éŸ³é¢‘
            cap = cv2.VideoCapture(video_path)
            
            # å°è¯•è·å–éŸ³é¢‘ä¿¡æ¯ï¼ˆOpenCVçš„é™åˆ¶ï¼Œå¯èƒ½éœ€è¦ffmpegï¼‰
            audio_info = {
                "has_audio": False,
                "audio_extracted": False,
                "note": "éœ€è¦ffmpegæ”¯æŒå®Œæ•´éŸ³é¢‘æå–"
            }
            
            cap.release()
            return audio_info
            
        except Exception as e:
            logger.warning(f"éŸ³é¢‘ä¿¡æ¯æå–å¤±è´¥: {e}")
            return {
                "has_audio": False,
                "error": str(e)
            }
    
    def _generate_video_analysis_summary(self, frame_analysis: List[Dict], duration: float, 
                                       total_frames: int, fps: float, audio_info: Dict) -> str:
        """ç”Ÿæˆè§†é¢‘åˆ†ææ‘˜è¦"""
        if not frame_analysis:
            return "æ— æ³•åˆ†æè§†é¢‘å†…å®¹"
        
        # åˆ†æè¿åŠ¨æ¨¡å¼
        motion_scores = [f["motion_score"] for f in frame_analysis]
        avg_motion = sum(motion_scores) / len(motion_scores)
        high_motion_frames = len([s for s in motion_scores if s > avg_motion * 1.5])
        
        # åˆ†æäº®åº¦å˜åŒ–
        brightness_scores = [f["brightness"] for f in frame_analysis]
        brightness_range = max(brightness_scores) - min(brightness_scores)
        
        # åˆ†æåœºæ™¯å¤æ‚åº¦
        complexity_scores = [f["scene_complexity"] for f in frame_analysis]
        avg_complexity = sum(complexity_scores) / len(complexity_scores)
        
        summary_parts = []
        
        # åŸºæœ¬ä¿¡æ¯
        summary_parts.append(f"è§†é¢‘æ—¶é•¿: {duration:.1f}ç§’")
        summary_parts.append(f"æ€»å¸§æ•°: {total_frames}å¸§")
        summary_parts.append(f"å¸§ç‡: {fps:.1f}fps")
        
        # è¿åŠ¨åˆ†æ
        if avg_motion < 20:
            summary_parts.append("è§†é¢‘å†…å®¹ç›¸å¯¹é™æ€")
        elif avg_motion < 50:
            summary_parts.append("è§†é¢‘åŒ…å«é€‚åº¦è¿åŠ¨")
        else:
            summary_parts.append("è§†é¢‘åŒ…å«å¤§é‡è¿åŠ¨æˆ–åœºæ™¯å˜åŒ–")
        
        if high_motion_frames > len(frame_analysis) * 0.3:
            summary_parts.append("æ£€æµ‹åˆ°å¤šä¸ªé«˜è¿åŠ¨åœºæ™¯")
        
        # äº®åº¦åˆ†æ
        if brightness_range > 100:
            summary_parts.append("åœºæ™¯äº®åº¦å˜åŒ–æ˜æ˜¾ï¼Œå¯èƒ½æœ‰ä¸åŒç¯å¢ƒæˆ–æ—¶é—´")
        elif brightness_range < 30:
            summary_parts.append("å…‰ç…§æ¡ä»¶ç›¸å¯¹ç¨³å®š")
        
        # åœºæ™¯å¤æ‚åº¦
        if avg_complexity > 0.1:
            summary_parts.append("åœºæ™¯å†…å®¹ä¸°å¯Œï¼ŒåŒ…å«è¾ƒå¤šç»†èŠ‚")
        else:
            summary_parts.append("åœºæ™¯ç›¸å¯¹ç®€å•")
        
        # éŸ³é¢‘ä¿¡æ¯
        if audio_info.get("has_audio"):
            summary_parts.append("è§†é¢‘åŒ…å«éŸ³é¢‘å†…å®¹")
        
        # æ—¶åºä¿¡æ¯
        if len(frame_analysis) > 1:
            start_time = frame_analysis[0]["time_formatted"]
            end_time = frame_analysis[-1]["time_formatted"]
            summary_parts.append(f"åˆ†ææ—¶é—´èŒƒå›´: {start_time} - {end_time}")
        
        return "ã€‚".join(summary_parts) + "ã€‚"

# åˆå§‹åŒ–å¤šæ¨¡æ€èŠå¤©æœºå™¨äººæœåŠ¡å’Œæ•°æ®åº“
if not GROQ_API_KEY:
    logger.warning("Groq APIå¯†é’¥æœªé…ç½®ï¼Œå¤šæ¨¡æ€åŠŸèƒ½å°†ä¸å¯ç”¨")

chatbot_service = MultiModalChatBotService(SILICONFLOW_API_KEY, GROQ_API_KEY, OPENAI_API_KEY)
chat_db = ChatDatabase()

# åšæŸ¥è”ç½‘æœç´¢æœåŠ¡ç±»
class BochaSearchService:
    """åšæŸ¥è”ç½‘æœç´¢æœåŠ¡ç±»"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or BOCHA_API_KEY
        self.base_url = "https://api.bochaai.com/v1/web-search"
        
    def search(self, query: str, count: int = 5, summary: bool = True, 
               freshness: str = "noLimit", include_images: bool = True) -> Dict:
        """
        ä½¿ç”¨åšæŸ¥APIè¿›è¡Œè”ç½‘æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            count: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5
            summary: æ˜¯å¦è¿”å›æ‘˜è¦ï¼Œé»˜è®¤True
            freshness: æ—¶é—´æ–°é²œåº¦ï¼Œå¯é€‰ oneDay, oneWeek, oneMonth, oneYear, noLimit
            include_images: æ˜¯å¦åŒ…å«å›¾ç‰‡ç»“æœ
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        if not self.api_key:
            return {
                "success": False,
                "error": "åšæŸ¥APIå¯†é’¥æœªé…ç½®",
                "results": []
            }
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "query": query,
            "count": count,
            "summary": summary,
            "freshness": freshness
        }
        
        try:
            logger.info(f"å¼€å§‹åšæŸ¥æœç´¢: {query}")
            response = requests.post(self.base_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            logger.info(f"åšæŸ¥APIå“åº”çŠ¶æ€: code={data.get('code')}, msg={data.get('msg')}")
            
            # æ£€æŸ¥APIå“åº”çŠ¶æ€
            if not isinstance(data, dict):
                raise ValueError(f"APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯: {type(data)}")
            
            # æ£€æŸ¥åšæŸ¥APIçš„å“åº”ä»£ç 
            if data.get('code') != 200:
                raise ValueError(f"åšæŸ¥APIè¿”å›é”™è¯¯: code={data.get('code')}, msg={data.get('msg')}")
                
            # è·å–å®é™…æ•°æ®
            api_data = data.get('data', {})
            if not isinstance(api_data, dict):
                raise ValueError(f"APIæ•°æ®å­—æ®µæ ¼å¼é”™è¯¯: {type(api_data)}")
            
            # è§£ææœç´¢ç»“æœ
            web_pages = []
            images = []
            
            # è§£æç½‘é¡µç»“æœ
            web_pages_data = api_data.get('webPages', {})
            if isinstance(web_pages_data, dict):
                web_pages = web_pages_data.get('value', [])
            
            # è§£æå›¾ç‰‡ç»“æœ 
            if include_images:
                images_data = api_data.get('images', {})
                if isinstance(images_data, dict):
                    images = images_data.get('value', [])
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for item in web_pages:
                if isinstance(item, dict):
                    formatted_results.append({
                        "title": item.get('name', item.get('title', '')),
                        "url": item.get('url', item.get('link', '')),
                        "snippet": item.get('snippet', item.get('description', item.get('summary', ''))),
                        "summary": item.get('summary', item.get('snippet', '')),
                        "siteName": item.get('siteName', item.get('source', '')),
                        "publishedDate": item.get('datePublished', item.get('date', ''))
                    })
            
            # æ ¼å¼åŒ–å›¾ç‰‡ç»“æœ
            image_results = []
            for img in images[:3]:  # é™åˆ¶å›¾ç‰‡æ•°é‡
                if isinstance(img, dict):
                    image_results.append({
                        "thumbnailUrl": img.get('thumbnailUrl', img.get('thumbnail', '')),
                        "contentUrl": img.get('contentUrl', img.get('url', '')),
                        "name": img.get('name', img.get('title', ''))
                    })
            
            logger.info(f"åšæŸ¥æœç´¢æˆåŠŸï¼Œè·å¾—{len(formatted_results)}ä¸ªç½‘é¡µç»“æœï¼Œ{len(image_results)}ä¸ªå›¾ç‰‡ç»“æœ")
            
            return {
                "success": True,
                "query": query,
                "results": formatted_results,
                "images": image_results,
                "total_count": len(formatted_results),
                "search_provider": "åšæŸ¥AI"
            }
            
        except requests.exceptions.RequestException as e:
            logger.error(f"åšæŸ¥æœç´¢APIè¯·æ±‚å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æœç´¢è¯·æ±‚å¤±è´¥: {str(e)}",
                "results": []
            }
        except Exception as e:
            logger.error(f"åšæŸ¥æœç´¢å¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æœç´¢å¤„ç†å¤±è´¥: {str(e)}",
                "results": []
            }
    
    def format_search_results_for_ai(self, search_result: Dict, max_results: int = 5) -> str:
        """
        å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºé€‚åˆAIæ·±åº¦ç†è§£å’Œåˆ†æçš„Markdownæ ¼å¼æ–‡æœ¬
        
        Args:
            search_result: æœç´¢ç»“æœå­—å…¸
            max_results: æœ€å¤§ç»“æœæ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„Markdownæœç´¢ç»“æœæ–‡æœ¬ï¼ŒåŒ…å«è¯¦ç»†å†…å®¹ä¾›AIåˆ†æ
        """
        if not search_result.get("success"):
            return f"æœç´¢å¤±è´¥: {search_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        results = search_result.get("results", [])
        query = search_result.get("query", "")
        
        if not results:
            return f"å¯¹äºæŸ¥è¯¢ '{query}' æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœã€‚"
        
        # æ„å»ºMarkdownæ ¼å¼çš„æœç´¢ç»“æœä¾›AIåˆ†æ
        formatted_text = f"""# ğŸ” è”ç½‘æœç´¢ç»“æœ

**æŸ¥è¯¢å…³é”®è¯:** {query}  
**æœç´¢æ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**æœç´¢å¼•æ“:** {search_result.get('search_provider', 'åšæŸ¥AI')}  
**ç»“æœæ€»æ•°:** {search_result.get('total_count', len(results))}

## ğŸ“Š æœç´¢ç»“æœè¯¦æƒ…

| åºå· | æ¥æºç½‘ç«™ | å‘å¸ƒæ—¶é—´ | æ ‡é¢˜ |
|------|----------|----------|------|"""
        
        # æ„å»ºè¡¨æ ¼å†…å®¹
        for i, result in enumerate(results[:max_results], 1):
            title = result.get("title", "æ— æ ‡é¢˜")
            site_name = result.get("siteName", "æœªçŸ¥æ¥æº")
            publish_date = result.get("publishedDate", "æœªçŸ¥æ—¶é—´")
            
            # æ¸…ç†æ ‡é¢˜ä¸­å¯èƒ½åŒ…å«çš„ç®¡é“ç¬¦å·ï¼Œé¿å…ç ´åè¡¨æ ¼æ ¼å¼
            title_clean = title.replace('|', '&#124;')[:50] + ('...' if len(title) > 50 else '')
            
            formatted_text += f"\n| {i} | {site_name} | {publish_date} | {title_clean} |"
        
        formatted_text += "\n\n"
        
        # è¯¦ç»†å¤„ç†æ¯ä¸ªæœç´¢ç»“æœ
        for i, result in enumerate(results[:max_results], 1):
            title = result.get("title", "æ— æ ‡é¢˜")
            snippet = result.get("snippet", "")
            summary = result.get("summary", "")
            url = result.get("url", "")
            site_name = result.get("siteName", "")
            publish_date = result.get("publishedDate", "")
            
            formatted_text += f"""### {i}. {title}

**æ¥æºç½‘ç«™:** {site_name}  
**å‘å¸ƒæ—¶é—´:** {publish_date}  
**é“¾æ¥:** [{url}]({url})

**å†…å®¹æ‘˜è¦:**
{summary if summary else snippet}

"""
            if snippet and summary:
                formatted_text += f"""**è¯¦ç»†æè¿°:**
{snippet}

"""
        
        # æ·»åŠ AIåˆ†ææŒ‡å¯¼
        analysis_guide = """---

## ğŸ¤– AIåˆ†ææŒ‡å¯¼

è¯·åŸºäºä»¥ä¸Šæœç´¢ç»“æœï¼ŒæŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œåˆ†æï¼š

1. **ğŸ“‹ æå–å…³é”®ä¿¡æ¯å’Œæ•°æ®**
2. **ğŸ“Š æ•´ç†æˆç»“æ„åŒ–çš„æ ¼å¼**ï¼ˆå¦‚è¡¨æ ¼ã€åˆ—è¡¨ç­‰ï¼‰
3. **ğŸ” åŒºåˆ†äº‹å®ä¿¡æ¯å’Œè§‚ç‚¹**
4. **ğŸ“š æä¾›å‡†ç¡®çš„æ¥æºå¼•ç”¨**  
5. **ğŸ’¹ å¦‚æœæ¶‰åŠæ•°æ®æˆ–ä»·æ ¼ä¿¡æ¯ï¼Œè¯·ç»„ç»‡æˆæ¸…æ™°çš„è¡¨æ ¼å½¢å¼**
6. **ğŸ“ æ€»ç»“æœ€é‡è¦çš„å‘ç°å’Œç»“è®º**

> **æ³¨æ„:** ä»¥ä¸Šä¿¡æ¯æ¥è‡ªå®æ—¶æœç´¢ï¼Œè¯·ç¡®ä¿å›ç­”çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚

**ğŸ“ æ ¼å¼è¦æ±‚:**
- ä½¿ç”¨ **Markdown æ ¼å¼** å›å¤ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€è¡¨æ ¼ã€åˆ—è¡¨ã€é“¾æ¥ç­‰
- å¯¹äºæ•°æ®å’Œä»·æ ¼ä¿¡æ¯ï¼Œ**å¿…é¡»ä½¿ç”¨è¡¨æ ¼æ ¼å¼**å‘ˆç°
- ä½¿ç”¨é€‚å½“çš„æ ‡é¢˜å±‚çº§ï¼ˆ##ã€###ï¼‰ç»„ç»‡å†…å®¹
- é‡è¦ä¿¡æ¯ä½¿ç”¨ **ç²—ä½“** å¼ºè°ƒ
- å¼•ç”¨æ¥æºæ—¶ä½¿ç”¨é“¾æ¥æ ¼å¼ï¼š[æ¥æºåç§°](é“¾æ¥åœ°å€)
- ä½¿ç”¨æ— åºåˆ—è¡¨ï¼ˆ-ï¼‰æˆ–æœ‰åºåˆ—è¡¨ï¼ˆ1.ï¼‰æ¥ç»„ç»‡è¦ç‚¹

**ç¤ºä¾‹æ ¼å¼:**
## ğŸ“Š ä»·æ ¼ä¿¡æ¯

| æ¥æºç½‘ç«™ | å‘å¸ƒæ—¶é—´ | ä»·æ ¼ï¼ˆå…ƒ/å…‹ï¼‰ |
|----------|----------|---------------|
| ç½‘ç«™A | 2024-XX-XX | XXX |
| ç½‘ç«™B | 2024-XX-XX | XXX |

## ğŸ”¢ æ•°å­¦è®¡ç®—ä¸å…¬å¼ï¼ˆå¦‚éœ€è¦ï¼‰

å¯¹äºæ¶‰åŠæ•°å­¦æ¦‚å¿µæˆ–è®¡ç®—çš„é—®é¢˜ï¼Œè¯·ä½¿ç”¨é€‚å½“çš„æ•°å­¦è¡¨è¾¾ï¼š

**è¡Œå†…å…¬å¼ç¤ºä¾‹ï¼š**
- å¹³å‡ä»·æ ¼ï¼š\\( \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i \\)
- å¢é•¿ç‡ï¼š\\( r = \\frac{V_f - V_i}{V_i} \\times 100\\% \\)

**å—çº§å…¬å¼ç¤ºä¾‹ï¼š**

\\[
\\text{æ³°å‹’å±•å¼€å¼} = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2!}(x-a)^2 + \\cdots
\\]

**æ•°å­¦æ¦‚å¿µè§£é‡Šæ ¼å¼ï¼š**
- ä½¿ç”¨ \\( \\) åŒ…å›´è¡Œå†…æ•°å­¦ç¬¦å·
- ä½¿ç”¨ \\[ \\] åŒ…å›´é‡è¦çš„å—çº§å…¬å¼
- ä¸ºå…¬å¼ä¸­çš„ç¬¦å·æä¾›æ¸…æ™°çš„è¯´æ˜

## ğŸ“ åˆ†æç»“è®º

1. **ä»·æ ¼è¶‹åŠ¿:** ...
2. **ä¸»è¦å‘ç°:** ...

## ğŸ“š å‚è€ƒæ¥æº

1. [æ¥æº1](é“¾æ¥1)
2. [æ¥æº2](é“¾æ¥2)
"""
        formatted_text += analysis_guide
        
        return formatted_text

# åˆå§‹åŒ–åšæŸ¥æœç´¢æœåŠ¡
bocha_search_service = BochaSearchService()

class FunctionCallExecutor:
    """Function Callingæ‰§è¡Œå™¨"""
    
    def __init__(self, bocha_search_service: BochaSearchService):
        self.bocha_search_service = bocha_search_service
    
    def get_available_tools(self) -> List[Dict]:
        """è·å–å¯ç”¨çš„å·¥å…·å®šä¹‰"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "web_search",
                    "description": "æœç´¢äº’è”ç½‘è·å–å®æ—¶ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–°é—»ã€ä»·æ ¼ã€å¤©æ°”ã€è‚¡ä»·ç­‰æœ€æ–°æ•°æ®ã€‚é€‚ç”¨äºéœ€è¦è·å–å½“å‰ä¿¡æ¯çš„é—®é¢˜ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æœç´¢æŸ¥è¯¢è¯ï¼Œåº”è¯¥ç®€æ´æ˜ç¡®ï¼Œä¾‹å¦‚ï¼š'é»„é‡‘ä»·æ ¼'ã€'ä¸Šæµ·å¤©æ°”'ã€'ç‰¹æ–¯æ‹‰è‚¡ä»·'ç­‰"
                            },
                            "count": {
                                "type": "integer",
                                "description": "è¿”å›æœç´¢ç»“æœçš„æ•°é‡ï¼Œé»˜è®¤ä¸º6ï¼Œæœ€å¤§ä¸º10",
                                "default": 6
                            },
                            "freshness": {
                                "type": "string",
                                "description": "æœç´¢ç»“æœçš„æ—¶æ•ˆæ€§è¦æ±‚",
                                "enum": ["noLimit", "day", "week", "month"],
                                "default": "week"
                            }
                        },
                        "required": ["query"]
                    }
                }
            }
        ]
    
    def execute_function(self, function_name: str, arguments: Dict) -> Dict:
        """æ‰§è¡Œå‡½æ•°è°ƒç”¨"""
        try:
            if function_name == "web_search":
                return self._execute_web_search(arguments)
            else:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥çš„å‡½æ•°: {function_name}"
                }
        except Exception as e:
            logger.error(f"æ‰§è¡Œå‡½æ•° {function_name} æ—¶å‡ºé”™: {e}")
            return {
                "success": False,
                "error": f"å‡½æ•°æ‰§è¡Œé”™è¯¯: {str(e)}"
            }
    
    def _execute_web_search(self, arguments: Dict) -> Dict:
        """æ‰§è¡Œç½‘ç»œæœç´¢"""
        query = arguments.get("query", "")
        count = arguments.get("count", 6)
        freshness = arguments.get("freshness", "week")
        
        if not query:
            return {
                "success": False,
                "error": "æœç´¢æŸ¥è¯¢ä¸èƒ½ä¸ºç©º"
            }
        
        # æ‰§è¡Œæœç´¢
        search_result = self.bocha_search_service.search(
            query=query,
            count=min(count, 10),  # é™åˆ¶æœ€å¤§æ•°é‡
            freshness=freshness,
            include_images=False,
            summary=True
        )
        
        if search_result.get('success'):
            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            formatted_text = self.bocha_search_service.format_search_results_for_ai(
                search_result, 
                max_results=count
            )
            return {
                "success": True,
                "result": formatted_text,
                "raw_results": search_result['results'][:count],
                "total_count": search_result.get('total_count', 0)
            }
        else:
            return {
                "success": False,
                "error": search_result.get('error', 'æœç´¢å¤±è´¥')
            }

# åˆå§‹åŒ–Function Callingæ‰§è¡Œå™¨
function_executor = FunctionCallExecutor(bocha_search_service)

def _preprocess_multimedia_messages(messages: List[Dict]) -> List[Dict]:
    """
    é¢„å¤„ç†å¤šåª’ä½“æ¶ˆæ¯ï¼Œæå–å¯åˆ†æçš„ä¿¡æ¯
    å°†éŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬ï¼Œè§†é¢‘æå–å…³é”®å¸§ç­‰
    """
    # å¤„ç†Noneæˆ–ç©ºè¾“å…¥
    if not messages:
        return []
    
    processed_messages = []
    
    for msg in messages:
        # åˆ›å»ºæ¶ˆæ¯çš„å‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        processed_msg = dict(msg)
        
        # ç¡®ä¿åŸºæœ¬å­—æ®µå­˜åœ¨
        if 'role' not in processed_msg:
            processed_msg['role'] = 'user'  # é»˜è®¤ä¸ºç”¨æˆ·è§’è‰²
        if 'text' not in processed_msg:
            processed_msg['text'] = ''  # é»˜è®¤ä¸ºç©ºæ–‡æœ¬
        
        if msg.get('role') == 'user':
            additional_text = []
            has_multimedia = False
            
            # å¤„ç†éŸ³é¢‘å†…å®¹ - ä½¿ç”¨Groq Speech-to-Text APIè¿›è¡Œè½¬å½•
            if msg.get('audio'):
                has_multimedia = True
                try:
                    # ä½¿ç”¨Groqçš„Speech-to-Text APIè¿›è¡Œè½¬å½•
                    transcription_result = chatbot_service.transcribe_audio_with_groq(msg['audio'], 'zh')
                    if transcription_result['success']:
                        transcribed_text = transcription_result['text']
                        if transcribed_text.strip():
                            additional_text.append(f"ç”¨æˆ·è¯­éŸ³å†…å®¹ï¼š\"{transcribed_text}\"")
                            additional_text.append("è¯·åˆ†æç”¨æˆ·çš„è¯­éŸ³å†…å®¹ï¼Œå¹¶æ ¹æ®è¯­éŸ³çš„è¯­è°ƒå’Œæƒ…æ„Ÿæä¾›é€‚å½“çš„å›åº”ã€‚")
                            logger.info(f"GroqéŸ³é¢‘è½¬å½•æˆåŠŸ: {transcribed_text[:50]}...")
                        else:
                            additional_text.append("ç”¨æˆ·æä¾›äº†ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œä½†æœªèƒ½è¯†åˆ«åˆ°æ¸…æ™°çš„è¯­éŸ³å†…å®¹ã€‚")
                    else:
                        # å¦‚æœGroqè½¬å½•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨OpenAI Whisperä½œä¸ºå¤‡é€‰
                        fallback_result = chatbot_service.transcribe_audio(msg['audio'], 'zh')
                        if fallback_result['success']:
                            transcribed_text = fallback_result['text']
                            additional_text.append(f"ç”¨æˆ·è¯­éŸ³å†…å®¹ï¼š\"{transcribed_text}\"")
                            logger.info(f"OpenAI Whisperå¤‡é€‰è½¬å½•æˆåŠŸ: {transcribed_text[:50]}...")
                        else:
                            additional_text.append("ç”¨æˆ·æä¾›äº†ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æ–‡å­—æè¿°æ¥åˆ†æéŸ³é¢‘å†…å®¹ã€‚")
                            logger.warning(f"æ‰€æœ‰éŸ³é¢‘è½¬å½•æ–¹æ³•éƒ½å¤±è´¥äº†")
                except Exception as e:
                    additional_text.append("ç”¨æˆ·æä¾›äº†ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æè¿°æ¥åˆ†æã€‚")
                    logger.error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                
                # ç§»é™¤éŸ³é¢‘æ•°æ®
                processed_msg.pop('audio', None)
            
            # å¤„ç†è§†é¢‘å†…å®¹ - æå–è§†é¢‘å¸§è¿›è¡Œåˆ†æ
            if msg.get('video'):
                has_multimedia = True
                try:
                    # å°è¯•ä»è§†é¢‘ä¸­æå–å…³é”®å¸§å’Œè¿›è¡Œå®Œæ•´åˆ†æ
                    frame_result = chatbot_service.extract_video_frames(msg['video'], max_frames=8)
                    if frame_result['success'] and frame_result.get('frames'):
                        # å°†æå–çš„ç¬¬ä¸€å¸§ä½œä¸ºä¸»è¦å›¾ç‰‡æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                        processed_msg['image'] = frame_result['frames'][0]
                        
                        # ç”Ÿæˆè¯¦ç»†çš„è§†é¢‘åˆ†ææç¤º
                        video_analysis_text = []
                        video_analysis_text.append(f"ç”¨æˆ·æä¾›äº†ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæˆ‘å·²ç»è¿›è¡Œäº†å®Œæ•´çš„è§†é¢‘åˆ†æï¼š")
                        
                        # åŸºæœ¬ä¿¡æ¯
                        video_analysis_text.append(f"ğŸ“Š è§†é¢‘ä¿¡æ¯ï¼š{frame_result.get('analysis_summary', 'æ— æ³•ç”Ÿæˆæ‘˜è¦')}")
                        
                        # å¸§åˆ†æè¯¦æƒ…
                        frame_analysis = frame_result.get('frame_analysis', [])
                        if frame_analysis:
                            video_analysis_text.append(f"ğŸ¬ å…³é”®å¸§åˆ†æï¼ˆå…±{len(frame_analysis)}å¸§ï¼‰ï¼š")
                            for i, frame_info in enumerate(frame_analysis[:3]):  # æ˜¾ç¤ºå‰3å¸§çš„è¯¦ç»†ä¿¡æ¯
                                time_info = frame_info.get('time_formatted', 'æœªçŸ¥')
                                position = frame_info.get('position', 'æœªçŸ¥ä½ç½®')
                                motion = frame_info.get('motion_score', 0)
                                brightness = frame_info.get('brightness', 0)
                                
                                motion_desc = "é™æ€" if motion < 20 else "ä¸­ç­‰è¿åŠ¨" if motion < 50 else "é«˜è¿åŠ¨"
                                light_desc = "è¾ƒæš—" if brightness < 80 else "é€‚ä¸­" if brightness < 180 else "è¾ƒäº®"
                                
                                video_analysis_text.append(f"  â€¢ {time_info}ï¼ˆ{position}ï¼‰- {motion_desc}ï¼Œå…‰çº¿{light_desc}")
                        
                        # è§†é¢‘ç»Ÿè®¡
                        video_stats = frame_result.get('video_stats', {})
                        if video_stats:
                            avg_motion = video_stats.get('avg_motion', 0)
                            scene_changes = video_stats.get('scene_changes', 0)
                            video_analysis_text.append(f"ğŸ“ˆ è¿åŠ¨ç»Ÿè®¡ï¼šå¹³å‡è¿åŠ¨å¼ºåº¦{avg_motion}ï¼Œåœºæ™¯å˜åŒ–{scene_changes}æ¬¡")
                        
                        # åˆ†æå»ºè®®
                        video_analysis_text.append("è¯·åŸºäºä»¥ä¸Šè§†é¢‘åˆ†æä¿¡æ¯å’Œæä¾›çš„å…³é”®å¸§å›¾åƒï¼Œè¿›è¡Œå…¨é¢çš„è§†é¢‘å†…å®¹åˆ†æã€‚")
                        video_analysis_text.append("é‡ç‚¹å…³æ³¨ï¼š1ï¼‰è§†é¢‘çš„æ—¶åºå‘å±• 2ï¼‰åœºæ™¯å˜åŒ– 3ï¼‰è¿åŠ¨æ¨¡å¼ 4ï¼‰æ•´ä½“æ•…äº‹æƒ…èŠ‚ã€‚")
                        
                        additional_text.extend(video_analysis_text)
                        logger.info(f"å®Œæ•´è§†é¢‘åˆ†ææˆåŠŸï¼Œæå–{len(frame_analysis)}å¸§ï¼Œæ—¶é•¿{frame_result.get('duration', 0)}ç§’")
                    else:
                        # è§†é¢‘åˆ†æå¤±è´¥çš„é™çº§å¤„ç†
                        additional_text.append("ç”¨æˆ·æä¾›äº†ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œä½†æ— æ³•è¿›è¡Œå®Œæ•´çš„è§†é¢‘åˆ†æã€‚")
                        additional_text.append("è¯·æ ¹æ®ç”¨æˆ·çš„æ–‡å­—æè¿°æ¥åˆ†æè§†é¢‘å†…å®¹ã€‚")
                        additional_text.append("å»ºè®®ç”¨æˆ·è¯¦ç»†æè¿°è§†é¢‘ä¸­çš„ï¼š1ï¼‰ä¸»è¦åœºæ™¯ 2ï¼‰äººç‰©åŠ¨ä½œ 3ï¼‰æ—¶é—´é¡ºåº 4ï¼‰å…³é”®äº‹ä»¶ã€‚")
                        logger.warning(f"è§†é¢‘åˆ†æå¤±è´¥: {frame_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                except Exception as e:
                    additional_text.append("ç”¨æˆ·æä¾›äº†ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æ–‡å­—æè¿°æ¥åˆ†æè§†é¢‘å†…å®¹ã€‚")
                    logger.error(f"è§†é¢‘å¤„ç†é”™è¯¯: {e}")
                
                # ç§»é™¤è§†é¢‘æ•°æ®
                processed_msg.pop('video', None)
            
            # åˆå¹¶æ–‡æœ¬å†…å®¹
            if additional_text:
                original_text = processed_msg.get('text', '')
                if original_text:
                    processed_msg['text'] = f"{original_text}\n\n{' '.join(additional_text)}"
                else:
                    processed_msg['text'] = ' '.join(additional_text)
            
            # å¦‚æœæœ‰å¤šåª’ä½“å†…å®¹ä½†æ²¡æœ‰æ–‡å­—æè¿°ï¼Œæ·»åŠ æ™ºèƒ½æç¤º
            if has_multimedia and not msg.get('text', '').strip():
                if msg.get('audio'):
                    processed_msg['text'] += "\n\nè¯·åŸºäºæˆ‘çš„è¯­éŸ³å†…å®¹æä¾›å¸®åŠ©å’Œå»ºè®®ã€‚"
                if msg.get('video'):
                    if msg.get('image'):  # å¦‚æœæˆåŠŸæå–äº†è§†é¢‘å¸§
                        processed_msg['text'] += "\n\nè¯·åˆ†æè¿™ä¸ªè§†é¢‘ç”»é¢ä¸­çš„å†…å®¹ã€‚"
                    else:
                        processed_msg['text'] += "\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£è¿™ä¸ªè§†é¢‘çš„å“ªäº›æ–¹é¢ï¼Ÿ"
        
        processed_messages.append(processed_msg)
    
    return processed_messages

def preprocess_chinese_date_terms(text: str) -> str:
    """
    é¢„å¤„ç†ä¸­æ–‡æ—¥æœŸè¯æ±‡ï¼Œå°†"ä»Šæ—¥"ã€"æ˜¨æ—¥"ç­‰è¯æ±‡è½¬æ¢ä¸ºå…·ä½“æ—¥æœŸ
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        
    Returns:
        å¤„ç†åçš„æ–‡æœ¬ï¼Œä¸­æ–‡æ—¥æœŸè¯æ±‡å·²è¢«æ›¿æ¢ä¸ºå…·ä½“æ—¥æœŸ
    """
    if not text:
        return text
    
    # è·å–å½“å‰æ—¶é—´
    now = datetime.now()
    today = now.date()
    
    processed_text = text
    
    # å¤„ç†ç›¸å¯¹æ—¥æœŸè¡¨è¾¾ (å¦‚: 3å¤©å‰, 2å¤©å)
    relative_patterns = [
        (r'(\d+)\s*å¤©å‰', lambda m: (today - timedelta(days=int(m.group(1)))).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        (r'(\d+)\s*å¤©å', lambda m: (today + timedelta(days=int(m.group(1)))).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        (r'(\d+)\s*å‘¨å‰', lambda m: (today - timedelta(weeks=int(m.group(1)))).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        (r'(\d+)\s*å‘¨å', lambda m: (today + timedelta(weeks=int(m.group(1)))).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        (r'(\d+)\s*ä¸ªæœˆå‰', lambda m: (today - timedelta(days=int(m.group(1)) * 30)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        (r'(\d+)\s*ä¸ªæœˆå', lambda m: (today + timedelta(days=int(m.group(1)) * 30)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
    ]
    
    for pattern, replacement_func in relative_patterns:
        def replace_match(match):
            original = match.group(0)
            converted_date = replacement_func(match)
            return f"{original}({converted_date})"
        
        processed_text = re.sub(pattern, replace_match, processed_text)
    
    # ç®€å•çš„è¯æ±‡æ˜ å°„ï¼Œä½¿ç”¨ä¸€æ¬¡æ€§æ›¿æ¢é¿å…é‡å¤
    simple_mappings = [
        ('ä»Šæ—¥', today.strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('ä»Šå¤©', today.strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('ä»Šå„¿', today.strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('ä»Šå„¿ä¸ª', today.strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜¨æ—¥', (today - timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜¨å¤©', (today - timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜¨å„¿', (today - timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜¨å„¿ä¸ª', (today - timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜æ—¥', (today + timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜å¤©', (today + timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜å„¿', (today + timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æ˜å„¿ä¸ª', (today + timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('å‰æ—¥', (today - timedelta(days=2)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('å‰å¤©', (today - timedelta(days=2)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('åæ—¥', (today + timedelta(days=2)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('åå¤©', (today + timedelta(days=2)).strftime('%Yå¹´%mæœˆ%dæ—¥')),
        ('æœ¬å‘¨', f"æœ¬å‘¨({today.strftime('%Yå¹´%mæœˆ%dæ—¥')}è¿™ä¸€å‘¨)"),
        ('è¿™å‘¨', f"è¿™å‘¨({today.strftime('%Yå¹´%mæœˆ%dæ—¥')}è¿™ä¸€å‘¨)"),
        ('è¿™ä¸€å‘¨', f"è¿™ä¸€å‘¨({today.strftime('%Yå¹´%mæœˆ%dæ—¥')}è¿™ä¸€å‘¨)"),
        ('ä¸Šå‘¨', f"ä¸Šå‘¨({(today - timedelta(days=7)).strftime('%Yå¹´%mæœˆ%dæ—¥')}é‚£ä¸€å‘¨)"),
        ('ä¸Šä¸€å‘¨', f"ä¸Šä¸€å‘¨({(today - timedelta(days=7)).strftime('%Yå¹´%mæœˆ%dæ—¥')}é‚£ä¸€å‘¨)"),
        ('ä¸‹å‘¨', f"ä¸‹å‘¨({(today + timedelta(days=7)).strftime('%Yå¹´%mæœˆ%dæ—¥')}é‚£ä¸€å‘¨)"),
        ('ä¸‹ä¸€å‘¨', f"ä¸‹ä¸€å‘¨({(today + timedelta(days=7)).strftime('%Yå¹´%mæœˆ%dæ—¥')}é‚£ä¸€å‘¨)"),
        ('æœ¬æœˆ', today.strftime('%Yå¹´%mæœˆ')),
        ('è¿™ä¸ªæœˆ', today.strftime('%Yå¹´%mæœˆ')),
        ('ä¸Šæœˆ', (today.replace(day=1) - timedelta(days=1)).strftime('%Yå¹´%mæœˆ')),
        ('ä¸Šä¸ªæœˆ', (today.replace(day=1) - timedelta(days=1)).strftime('%Yå¹´%mæœˆ')),
        ('ä¸‹æœˆ', (today.replace(day=28) + timedelta(days=4)).replace(day=1).strftime('%Yå¹´%mæœˆ')),
        ('ä¸‹ä¸ªæœˆ', (today.replace(day=28) + timedelta(days=4)).replace(day=1).strftime('%Yå¹´%mæœˆ')),
        ('ç°åœ¨', now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')),
        ('æ­¤æ—¶', now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')),
        ('å½“å‰', now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')),
        ('ç›®å‰', now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')),
    ]
    
    # æŒ‰ç…§è¯æ±‡é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œé¿å…çŸ­è¯æ±‡å…ˆåŒ¹é…å¯¼è‡´é•¿è¯æ±‡æ— æ³•åŒ¹é…
    simple_mappings.sort(key=lambda x: len(x[0]), reverse=True)
    
    for chinese_term, replacement in simple_mappings:
        if chinese_term in processed_text:
            processed_text = processed_text.replace(chinese_term, replacement)
    
    # å¤„ç†æ˜ŸæœŸç›¸å…³
    weekdays = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
    chinese_weekdays = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
    
    current_weekday = today.weekday()  # 0=Monday, 6=Sunday
    
    for i, (short_name, long_name) in enumerate(zip(weekdays, chinese_weekdays)):
        days_diff = i - current_weekday
        target_date = today + timedelta(days=days_diff)
        date_str = target_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        # å¦‚æœæ˜¯æœ¬å‘¨çš„æŸä¸€å¤©ï¼Œæ ‡æ³¨ä¸ºæœ¬å‘¨
        if abs(days_diff) <= 3:  # å‰å3å¤©å†…è®¤ä¸ºæ˜¯æœ¬å‘¨
            week_indicator = "æœ¬å‘¨" if days_diff >= 0 else "ä¸Šå‘¨" if days_diff < -3 else "æœ¬å‘¨"
            if short_name in processed_text:
                processed_text = processed_text.replace(short_name, f"{short_name}({week_indicator}{date_str})")
            if long_name in processed_text:
                processed_text = processed_text.replace(long_name, f"{long_name}({week_indicator}{date_str})")
    
    return processed_text

@app.route('/')
def index():
    """æä¾›å‰ç«¯é¡µé¢"""
    return send_from_directory('.', 'index.html')

@app.route('/api/models', methods=['GET'])
def get_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    # æ ¹æ®APIå¯†é’¥å¯ç”¨æ€§è¿‡æ»¤æ¨¡å‹
    available_models = []
    for model in AVAILABLE_MODELS:
        if model["provider"] == "siliconflow" and SILICONFLOW_API_KEY:
            available_models.append(model)
        elif model["provider"] == "groq" and GROQ_API_KEY:
            available_models.append(model)
    
    return jsonify({
        'success': True,
        'models': available_models,
        'capabilities': {
            'text_chat': bool(SILICONFLOW_API_KEY),
            'image_analysis': bool(GROQ_API_KEY),
            'multimodal': bool(GROQ_API_KEY)
        }
    })

@app.route('/api/chat', methods=['POST'])
def chat():
    """å¤„ç†èŠå¤©è¯·æ±‚ï¼Œæ”¯æŒFunction Calling"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'
            }), 400
        
        messages = data.get('messages', [])
        model = data.get('model', 'deepseek-ai/DeepSeek-V2.5')
        session_id = data.get('session_id')  # å¯é€‰çš„ä¼šè¯ID
        system_prompt = data.get('system_prompt')  # ç³»ç»Ÿæç¤º
        temperature = data.get('temperature', 0.7)  # æ¸©åº¦å‚æ•°
        enable_search = data.get('enable_search', True)  # æ˜¯å¦å¯ç”¨æœç´¢åŠŸèƒ½
        
        if not messages:
            return jsonify({
                'success': False,
                'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # éªŒè¯temperatureå‚æ•°
        if not isinstance(temperature, (int, float)) or not (0 <= temperature <= 2):
            temperature = 0.7
        
        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ç”¨äºå­˜å‚¨
        last_user_message = None
        for msg in reversed(messages):
            if msg.get('role') == 'user':
                last_user_message = msg
                break
        
        # é¢„å¤„ç†ç”¨æˆ·æ¶ˆæ¯ä¸­çš„æ—¥æœŸè¯æ±‡
        for message in messages:
            if message.get('role') == 'user' and message.get('text'):
                original_text = message['text']
                processed_text = preprocess_chinese_date_terms(original_text)
                if processed_text != original_text:
                    message['text'] = processed_text
                    logger.info(f"æ—¥æœŸé¢„å¤„ç†: '{original_text}' -> '{processed_text}'")
        
        # é¢„å¤„ç†å¤šåª’ä½“å†…å®¹ï¼Œæå–å¯åˆ†æçš„ä¿¡æ¯
        processed_messages = _preprocess_multimedia_messages(messages)
        
        # å¦‚æœå¯ç”¨æœç´¢ï¼Œä½¿ç”¨æ™ºèƒ½åˆ¤æ–­æ¨¡å¼
        if enable_search:
            # å…ˆè®©AIåˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
            enhanced_system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥é€‰æ‹©æ€§åœ°ä½¿ç”¨ç½‘ç»œæœç´¢æ¥å›ç­”é—®é¢˜ã€‚å…·å¤‡ä¼˜é›…çš„ChatGPTå¼å›ç­”é£æ ¼ã€‚

ğŸ¯ åˆ¤æ–­è§„åˆ™ï¼š
å¦‚æœé—®é¢˜æ¶‰åŠä»¥ä¸‹å†…å®¹ï¼Œè¯·å›å¤"SEARCH_REQUIRED:"åè·Ÿæœç´¢å…³é”®è¯ï¼š
- å®æ—¶ä¿¡æ¯ï¼ˆå¦‚å½“å‰æ—¶é—´ã€æ—¥æœŸã€ä»·æ ¼ã€è‚¡ä»·ã€æ±‡ç‡ï¼‰
- æœ€æ–°æ–°é—»ã€äº‹ä»¶
- å¤©æ°”ä¿¡æ¯
- ä½“è‚²èµ›äº‹ç»“æœ
- äº§å“ä»·æ ¼ã€å¸‚åœºè¡Œæƒ…
- å½“å‰æ”¿ç­–æ³•è§„
- æœ€æ–°æŠ€æœ¯å‘å±•

å¦‚æœæ˜¯ä¸€èˆ¬çŸ¥è¯†ã€ç¼–ç¨‹å¸®åŠ©ã€åˆ›æ„å†™ä½œã€æ•°å­¦æ¦‚å¿µç­‰ä¸éœ€è¦å®æ—¶ä¿¡æ¯çš„å†…å®¹ï¼Œè¯·ç›´æ¥å›ç­”ã€‚

ğŸ“ å¯¹äºæ•°å­¦/ç§‘å­¦æ¦‚å¿µï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

**CRITICAL: ç›´æ¥ä½¿ç”¨LaTeXåˆ†éš”ç¬¦ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•å ä½ç¬¦ï¼**

## ğŸ“š æ¦‚å¿µå®šä¹‰
[ç®€æ´æ¸…æ™°çš„å®šä¹‰]

## ğŸ”¢ æ•°å­¦è¡¨è¾¾

$$
[åœ¨è¿™é‡Œå†™å®Œæ•´çš„LaTeXå…¬å¼ï¼Œä¸è¦ä½¿ç”¨å ä½ç¬¦]
$$

å…¶ä¸­ï¼š
- \\( å…·ä½“ç¬¦å· \\) è¡¨ç¤ºå…·ä½“å«ä¹‰
- \\( å…·ä½“ç¬¦å· \\) è¡¨ç¤ºå…·ä½“å«ä¹‰

## ğŸ’¡ ç›´è§‚ç†è§£
[ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å’Œæ¯”å–»è§£é‡Š]

## ğŸ“– ç»å…¸ä¾‹å­
| å‡½æ•° | å±•å¼€å¼ | ç‰¹ç‚¹ | åº”ç”¨ |
|------|--------|------|------|
| \\( e^x \\) | \\( 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots \\) | æ”¶æ•›å¿« | æŒ‡æ•°å¢é•¿ |

## ğŸš€ å®é™…åº”ç”¨
- **é¢†åŸŸ1**: å…·ä½“åº”ç”¨è¯´æ˜
- **é¢†åŸŸ2**: å…·ä½“åº”ç”¨è¯´æ˜

## ğŸ’­ æ·±å…¥æ€è€ƒ
[å¯å‘æ€§çš„æ€è€ƒç‚¹æˆ–ç›¸å…³æ¦‚å¿µ]

**é‡è¦æç¤º**: 
- å¿…é¡»ä½¿ç”¨ \\( \\) åŒ…å›´è¡Œå†…æ•°å­¦å…¬å¼
- å¿…é¡»ä½¿ç”¨ $$ $$ åŒ…å›´å—çº§æ•°å­¦å…¬å¼ï¼ˆå‰åæ¢è¡Œï¼‰
- ç»å¯¹ä¸è¦ä½¿ç”¨MATH_LATEX_BLOCK_Xæˆ–MATH_LATEX_INLINE_Xè¿™æ ·çš„å ä½ç¬¦
- ç›´æ¥è¾“å‡ºLaTeXä»£ç 

ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼š"é»„é‡‘ä»·æ ¼æ˜¯å¤šå°‘" â†’ å›å¤ï¼š"SEARCH_REQUIRED:é»„é‡‘ä»·æ ¼"
ç”¨æˆ·ï¼š"ä»€ä¹ˆæ˜¯æ³°å‹’å±•å¼€å¼" â†’ ç›´æ¥ç”¨ä¸Šè¿°æ ¼å¼è¯¦ç»†å›ç­”
ç”¨æˆ·ï¼š"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·" â†’ å›å¤ï¼š"SEARCH_REQUIRED:ä»Šå¤©å¤©æ°”"
ç”¨æˆ·ï¼š"å†™ä¸€é¦–è¯—" â†’ ç›´æ¥åˆ›ä½œè¯—æ­Œ"""
            
            # ä½¿ç”¨å¢å¼ºçš„ç³»ç»Ÿæç¤º
            final_system_prompt = enhanced_system_prompt if not system_prompt else f"{enhanced_system_prompt}\n\n{system_prompt}"
            
            # è·å–AIåˆ¤æ–­
            result = chatbot_service.get_response(processed_messages, model, final_system_prompt, temperature)
            
            if not result['success']:
                # AIåˆ¤æ–­å¤±è´¥ï¼Œè¿”å›é”™è¯¯
                return jsonify({
                    'success': False,
                    'error': f'AIåˆ¤æ–­å¤±è´¥: {result.get("error")}'
                }), 500
            
            if result['success']:
                response_text = result['response']
                
                # æ£€æŸ¥AIæ˜¯å¦æŒ‡ç¤ºéœ€è¦æœç´¢
                if response_text.startswith("SEARCH_REQUIRED:"):
                    search_query = response_text.replace("SEARCH_REQUIRED:", "").strip()
                    logger.info(f"AIåˆ¤æ–­éœ€è¦æœç´¢: {search_query}")
                    
                    # æ‰§è¡Œæœç´¢
                    search_result = function_executor.execute_function("web_search", {"query": search_query})
                    
                    if search_result['success']:
                        # æ„å»ºåŒ…å«æœç´¢ç»“æœçš„æ–°æ¶ˆæ¯
                        search_enhanced_messages = processed_messages.copy()
                        search_enhanced_messages.append({
                            "role": "assistant", 
                            "text": f"æˆ‘éœ€è¦æœç´¢ '{search_query}' æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
                        })
                        search_enhanced_messages.append({
                            "role": "system", 
                            "text": f"æœç´¢ç»“æœï¼š\n{search_result['result']}\n\nè¯·åŸºäºä»¥ä¸Šæœç´¢ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›å‡†ç¡®ã€è¯¦ç»†çš„ä¿¡æ¯ã€‚å¦‚æœæ¶‰åŠä»·æ ¼æ•°æ®ï¼Œè¯·æ•´ç†æˆè¡¨æ ¼æ ¼å¼ã€‚"
                        })
                        
                        # é‡æ–°ç”Ÿæˆæœ€ç»ˆå›å¤
                        final_result = chatbot_service.get_response(search_enhanced_messages, model, system_prompt, temperature)
                        
                        if final_result['success']:
                            # ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
                            if session_id and last_user_message:
                                _save_chat_messages(session_id, last_user_message, final_result, model)
                            
                            return jsonify({
                                'success': True,
                                'response': final_result['response'],
                                'provider': final_result.get('provider'),
                                'model': final_result.get('model'),
                                'session_id': session_id,
                                'search_performed': True,
                                'search_query': search_query
                            })
                        else:
                            return jsonify({
                                'success': False,
                                'error': f'æœç´¢åç”Ÿæˆå›å¤å¤±è´¥: {final_result.get("error")}'
                            }), 500
                    else:
                        # æœç´¢å¤±è´¥ï¼Œè¿”å›æç¤º
                        fallback_response = f"æˆ‘è®¤ä¸ºéœ€è¦æœç´¢ '{search_query}' æ¥å›ç­”æ‚¨çš„é—®é¢˜ï¼Œä½†æœç´¢åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•ï¼Œæˆ–è€…æ‚¨å¯ä»¥æä¾›æ›´å¤šå…·ä½“ä¿¡æ¯ã€‚"
                        
                        if session_id and last_user_message:
                            _save_chat_messages(session_id, last_user_message, {'response': fallback_response}, model)
                        
                        return jsonify({
                            'success': True,
                            'response': fallback_response,
                            'provider': result.get('provider'),
                            'model': result.get('model'),
                            'session_id': session_id,
                            'search_attempted': True,
                            'search_failed': True
                        })
                else:
                    # AIç›´æ¥å›ç­”ï¼Œä¸éœ€è¦æœç´¢
                    if session_id and last_user_message:
                        _save_chat_messages(session_id, last_user_message, result, model)
                    
                    return jsonify({
                        'success': True,
                        'response': result['response'],
                        'provider': result.get('provider'),
                        'model': result.get('model'),
                        'session_id': session_id,
                        'search_performed': False
                    })
        else:
            # ä¸å¯ç”¨æœç´¢ï¼Œä½¿ç”¨åŸå§‹ç³»ç»Ÿæç¤º
            result = chatbot_service.get_response(processed_messages, model, system_prompt, temperature)
            
            if result['success']:
                # æ™®é€šå›å¤ï¼Œä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
                if session_id and last_user_message:
                    _save_chat_messages(session_id, last_user_message, result, model)
                
                return jsonify({
                    'success': True,
                    'response': result['response'],
                    'provider': result.get('provider'),
                    'model': result.get('model'),
                    'session_id': session_id
                })
            else:
                return jsonify({
                    'success': False,
                    'error': result['error']
                }), 500
            
    except Exception as e:
        logger.error(f"èŠå¤©APIé”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}'
        }), 500

def _handle_tool_calls(result: Dict, messages: List[Dict], model: str, system_prompt: str, temperature: float, session_id: str = None) -> Dict:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    try:
        tool_calls = result.get('tool_calls', [])
        tool_results = []
        
        # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        for tool_call in tool_calls:
            function_name = tool_call['function']['name']
            arguments = json.loads(tool_call['function']['arguments'])
            
            logger.info(f"æ‰§è¡Œå·¥å…·è°ƒç”¨: {function_name}, å‚æ•°: {arguments}")
            
            # æ‰§è¡Œå·¥å…·
            tool_result = function_executor.execute_function(function_name, arguments)
            
            # æ„å»ºå·¥å…·ç»“æœæ¶ˆæ¯
            tool_message = {
                "role": "tool",
                "tool_call_id": tool_call['id'],
                "content": json.dumps(tool_result, ensure_ascii=False) if tool_result['success'] else f"å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_result['error']}"
            }
            tool_results.append(tool_message)
        
        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯åºåˆ—
        enhanced_messages = messages.copy()
        enhanced_messages.append(result['message'])  # AIçš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
        enhanced_messages.extend(tool_results)  # å·¥å…·æ‰§è¡Œç»“æœ
        
        # é‡æ–°è°ƒç”¨AIè·å–æœ€ç»ˆå›å¤
        final_result = chatbot_service.get_response(enhanced_messages, model, system_prompt, temperature)
        
        if final_result['success']:
            # ä¿å­˜å®Œæ•´çš„å¯¹è¯å†å²
            if session_id:
                # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                last_user_message = None
                for msg in reversed(messages):
                    if msg.get('role') == 'user':
                        last_user_message = msg
                        break
                
                if last_user_message:
                    _save_chat_messages(session_id, last_user_message, final_result, model)
            
            return {
                'success': True,
                'response': final_result['response'],
                'provider': final_result.get('provider'),
                'model': final_result.get('model'),
                'session_id': session_id,
                'tool_calls_executed': len(tool_calls),
                'search_performed': any(tc['function']['name'] == 'web_search' for tc in tool_calls)
            }
        else:
            return {
                'success': False,
                'error': f'è·å–æœ€ç»ˆå›å¤å¤±è´¥: {final_result.get("error")}',
                'tool_calls_executed': len(tool_calls)
            }
            
    except Exception as e:
        logger.error(f"å¤„ç†å·¥å…·è°ƒç”¨é”™è¯¯: {e}")
        return {
            'success': False,
            'error': f'å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {str(e)}'
        }

def _save_chat_messages(session_id: str, last_user_message: Dict, result: Dict, model: str):
    """ä¿å­˜èŠå¤©æ¶ˆæ¯åˆ°æ•°æ®åº“"""
    try:
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_content = last_user_message.get('text', '')
        user_image = last_user_message.get('image')
        user_audio = last_user_message.get('audio')
        user_video = last_user_message.get('video')
        
        # ç¡®å®šå†…å®¹ç±»å‹
        if user_image:
            content_type = 'image'
            media_data = user_image
        elif user_audio:
            content_type = 'audio'
            media_data = user_audio
        elif user_video:
            content_type = 'video'
            media_data = user_video
        else:
            content_type = 'text'
            media_data = None
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_name = None
        file_size = None
        if user_audio or user_video:
            # ä»data URLä¸­æå–æ–‡ä»¶å¤§å°ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
            if media_data:
                try:
                    # ä»base64æ•°æ®ä¸­ä¼°ç®—æ–‡ä»¶å¤§å°
                    base64_data = media_data.split(',')[1] if ',' in media_data else media_data
                    file_size = len(base64_data) * 3 // 4  # base64è§£ç åçš„å¤§å°
                except:
                    pass
        
        chat_db.add_message(
            session_id=session_id,
            role='user',
            content=user_content,
            content_type=content_type,
            image_data=media_data,  # ç°åœ¨ç”¨äºå­˜å‚¨æ‰€æœ‰ç±»å‹çš„åª’ä½“æ•°æ®
            model=model,
            file_name=file_name,
            file_size=file_size
        )
        
        # ä¿å­˜AIå›å¤
        chat_db.add_message(
            session_id=session_id,
            role='assistant',
            content=result['response'],
            content_type='text',
            model=result.get('model'),
            provider=result.get('provider')
        )
    except Exception as e:
        logger.error(f"ä¿å­˜èŠå¤©æ¶ˆæ¯å¤±è´¥: {e}")

@app.route('/api/upload', methods=['POST'])
def upload_image():
    """å¤„ç†å›¾ç‰‡ä¸Šä¼ """
    try:
        if 'image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶'
            }), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'webp'}
        if '.' not in file.filename or file.filename.rsplit('.', 1)[1].lower() not in allowed_extensions:
            return jsonify({
                'success': False,
                'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  PNGã€JPGã€JPEGã€GIF æˆ– WebP æ ¼å¼çš„å›¾ç‰‡'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å° (4MBé™åˆ¶)
        file.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
        file_size = file.tell()
        file.seek(0)  # å›åˆ°æ–‡ä»¶å¼€å¤´
        
        if file_size > 4 * 1024 * 1024:  # 4MB
            return jsonify({
                'success': False,
                'error': f'æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024:.1f}MB)ï¼Œæœ€å¤§æ”¯æŒ4MB'
            }), 400
        
        # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
        file_content = file.read()
        file_base64 = base64.b64encode(file_content).decode('utf-8')
        
        # è·å–æ–‡ä»¶MIMEç±»å‹
        file_extension = file.filename.rsplit('.', 1)[1].lower()
        mime_type = f"image/{file_extension if file_extension != 'jpg' else 'jpeg'}"
        
        # æ„é€ data URL
        data_url = f"data:{mime_type};base64,{file_base64}"
        
        return jsonify({
            'success': True,
            'image_data': data_url,
            'file_size': file_size,
            'file_name': file.filename
        })
        
    except Exception as e:
        logger.error(f"å›¾ç‰‡ä¸Šä¼ é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/upload/audio', methods=['POST'])
def upload_audio():
    """å¤„ç†éŸ³é¢‘ä¸Šä¼ """
    try:
        if 'audio' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶'
            }), 400
        
        file = request.files['audio']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'mp3', 'wav', 'ogg', 'm4a', 'aac', 'flac', 'webm'}
        if '.' not in file.filename or file.filename.rsplit('.', 1)[1].lower() not in allowed_extensions:
            return jsonify({
                'success': False,
                'error': 'ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼Œè¯·ä¸Šä¼  MP3ã€WAVã€OGGã€M4Aã€AACã€FLAC æˆ– WebM æ ¼å¼çš„éŸ³é¢‘'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å° (10MBé™åˆ¶)
        file.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
        file_size = file.tell()
        file.seek(0)  # å›åˆ°æ–‡ä»¶å¼€å¤´
        
        if file_size > 10 * 1024 * 1024:  # 10MB
            return jsonify({
                'success': False,
                'error': f'éŸ³é¢‘æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024:.1f}MB)ï¼Œæœ€å¤§æ”¯æŒ10MB'
            }), 400
        
        # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
        file_content = file.read()
        file_base64 = base64.b64encode(file_content).decode('utf-8')
        
        # è·å–æ–‡ä»¶MIMEç±»å‹
        file_extension = file.filename.rsplit('.', 1)[1].lower()
        mime_type = f"audio/{file_extension if file_extension != 'm4a' else 'mp4'}"
        
        # æ„é€ data URL
        data_url = f"data:{mime_type};base64,{file_base64}"
        
        return jsonify({
            'success': True,
            'audio_data': data_url,
            'file_size': file_size,
            'file_name': file.filename,
            'duration': None  # TODO: å¯ä»¥ä½¿ç”¨librosaæˆ–ffmpegè·å–éŸ³é¢‘æ—¶é•¿
        })
        
    except Exception as e:
        logger.error(f"éŸ³é¢‘ä¸Šä¼ é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'éŸ³é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/upload/video', methods=['POST'])
def upload_video():
    """å¤„ç†è§†é¢‘ä¸Šä¼ """
    try:
        if 'video' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶'
            }), 400
        
        file = request.files['video']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'mp4', 'avi', 'mov', 'wmv', 'flv', 'webm', 'mkv'}
        if '.' not in file.filename or file.filename.rsplit('.', 1)[1].lower() not in allowed_extensions:
            return jsonify({
                'success': False,
                'error': 'ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼ï¼Œè¯·ä¸Šä¼  MP4ã€AVIã€MOVã€WMVã€FLVã€WebM æˆ– MKV æ ¼å¼çš„è§†é¢‘'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å° (50MBé™åˆ¶)
        file.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
        file_size = file.tell()
        file.seek(0)  # å›åˆ°æ–‡ä»¶å¼€å¤´
        
        if file_size > 50 * 1024 * 1024:  # 50MB
            return jsonify({
                'success': False,
                'error': f'è§†é¢‘æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024:.1f}MB)ï¼Œæœ€å¤§æ”¯æŒ50MB'
            }), 400
        
        # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
        file_content = file.read()
        file_base64 = base64.b64encode(file_content).decode('utf-8')
        
        # è·å–æ–‡ä»¶MIMEç±»å‹
        file_extension = file.filename.rsplit('.', 1)[1].lower()
        mime_type = f"video/{file_extension}"
        
        # æ„é€ data URL
        data_url = f"data:{mime_type};base64,{file_base64}"
        
        return jsonify({
            'success': True,
            'video_data': data_url,
            'file_size': file_size,
            'file_name': file.filename,
            'duration': None  # TODO: å¯ä»¥ä½¿ç”¨ffmpegè·å–è§†é¢‘æ—¶é•¿
        })
        
    except Exception as e:
        logger.error(f"è§†é¢‘ä¸Šä¼ é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/upload/record', methods=['POST'])
def upload_recording():
    """å¤„ç†å½•éŸ³ä¸Šä¼ å¹¶è½¬æ¢ä¸ºæ–‡å­—"""
    try:
        data = request.get_json()
        if not data or 'audio_data' not in data:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ•°æ®'
            }), 400
        
        audio_data = data['audio_data']
        language = data.get('language', 'zh')  # é»˜è®¤ä¸­æ–‡
        transcribe = data.get('transcribe', True)  # æ˜¯å¦è½¬å½•ï¼Œé»˜è®¤ä¸ºTrue
        client_transcript = data.get('transcript')  # å®¢æˆ·ç«¯æä¾›çš„è½¬å½•æ–‡æœ¬
        
        # éªŒè¯base64æ•°æ®
        if not audio_data.startswith('data:audio/'):
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼'
            }), 400
        
        # æå–base64å†…å®¹
        try:
            header, base64_content = audio_data.split(',', 1)
            audio_bytes = base64.b64decode(base64_content)
            file_size = len(audio_bytes)
        except Exception:
            return jsonify({
                'success': False,
                'error': 'éŸ³é¢‘æ•°æ®è§£æå¤±è´¥'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å° (5MBé™åˆ¶)
        if file_size > 5 * 1024 * 1024:  # 5MB
            return jsonify({
                'success': False,
                'error': f'å½•éŸ³æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024:.1f}MB)ï¼Œæœ€å¤§æ”¯æŒ5MB'
            }), 400
        
        # åŸºæœ¬å“åº”æ•°æ®
        response_data = {
            'success': True,
            'audio_data': audio_data,
            'file_size': file_size,
            'file_name': f"å½•éŸ³_{datetime.now().strftime('%Y%m%d_%H%M%S')}.webm"
        }
        
        # å¦‚æœéœ€è¦è½¬å½•ï¼Œè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
        if transcribe:
            # ä¼˜å…ˆä½¿ç”¨å®¢æˆ·ç«¯æä¾›çš„è½¬å½•æ–‡æœ¬ï¼ˆæµè§ˆå™¨è¯­éŸ³APIï¼‰
            if client_transcript:
                logger.info("ä½¿ç”¨å®¢æˆ·ç«¯è¯­éŸ³è¯†åˆ«ç»“æœ...")
                fallback_result = chatbot_service.transcribe_audio_fallback(audio_data, client_transcript)
                
                if fallback_result['success']:
                    response_data.update({
                        'transcription': {
                            'text': fallback_result['text'],
                            'language': fallback_result['language'],
                            'model': fallback_result['model'],
                            'source': 'browser-speech-api'
                        }
                    })
                    logger.info(f"å®¢æˆ·ç«¯è¯­éŸ³è¯†åˆ«æˆåŠŸ: {fallback_result['text'][:50]}...")
                else:
                    response_data['transcription_error'] = fallback_result['error']
            else:
                # ä½¿ç”¨æœåŠ¡ç«¯OpenAI Whisper API
                logger.info("å¼€å§‹æœåŠ¡ç«¯è¯­éŸ³è½¬æ–‡å­—...")
                transcription_result = chatbot_service.transcribe_audio(audio_data, language)
                
                if transcription_result['success']:
                    response_data.update({
                        'transcription': {
                            'text': transcription_result['text'],
                            'language': transcription_result['language'],
                            'duration': transcription_result.get('duration'),
                            'model': transcription_result.get('model'),
                            'source': 'openai-whisper'
                        }
                    })
                    logger.info(f"æœåŠ¡ç«¯è¯­éŸ³è½¬æ–‡å­—æˆåŠŸ: {transcription_result['text'][:50]}...")
                else:
                    logger.warning(f"æœåŠ¡ç«¯è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {transcription_result['error']}")
                    response_data['transcription_error'] = transcription_result['error']
                    
                    # å¦‚æœOpenAI APIä¸å¯ç”¨ï¼Œæä¾›å¤‡ç”¨å»ºè®®
                    if transcription_result.get('fallback_available'):
                        response_data['fallback_suggestion'] = transcription_result.get('fallback_message')
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"å½•éŸ³ä¸Šä¼ é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'å½•éŸ³ä¸Šä¼ å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/transcribe', methods=['POST'])
def transcribe_audio_api():
    """ä¸“é—¨çš„è¯­éŸ³è½¬æ–‡å­—APIç«¯ç‚¹"""
    try:
        data = request.get_json()
        if not data or 'audio_data' not in data:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ•°æ®'
            }), 400
        
        audio_data = data['audio_data']
        language = data.get('language', 'zh')  # é»˜è®¤ä¸­æ–‡
        
        # éªŒè¯base64æ•°æ®
        if not audio_data.startswith('data:audio/'):
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼'
            }), 400
        
        logger.info(f"å¼€å§‹è¯­éŸ³è½¬æ–‡å­—ï¼Œè¯­è¨€: {language}")
        result = chatbot_service.transcribe_audio(audio_data, language)
        
        if result['success']:
            logger.info(f"è¯­éŸ³è½¬æ–‡å­—æˆåŠŸ: {result['text'][:100]}...")
            return jsonify({
                'success': True,
                'text': result['text'],
                'language': result['language'],
                'duration': result.get('duration'),
                'model': result.get('model')
            })
        else:
            logger.error(f"è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {result['error']}")
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500
        
    except Exception as e:
        logger.error(f"è¯­éŸ³è½¬æ–‡å­—APIé”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/sessions', methods=['GET'])
def get_sessions():
    """è·å–å¯¹è¯ä¼šè¯åˆ—è¡¨"""
    try:
        page = int(request.args.get('page', 1))
        limit = int(request.args.get('limit', 20))
        offset = (page - 1) * limit
        
        sessions = chat_db.get_sessions(limit=limit, offset=offset)
        statistics = chat_db.get_statistics()
        
        return jsonify({
            'success': True,
            'sessions': sessions,
            'statistics': statistics,
            'pagination': {
                'page': page,
                'limit': limit,
                'has_more': len(sessions) == limit
            }
        })
        
    except Exception as e:
        logger.error(f"è·å–ä¼šè¯åˆ—è¡¨é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/sessions', methods=['POST'])
def create_session():
    """åˆ›å»ºæ–°çš„å¯¹è¯ä¼šè¯"""
    try:
        data = request.get_json()
        title = data.get('title') if data else None
        model = data.get('model') if data else None
        
        session_id = chat_db.create_session(title=title, model=model)
        session = chat_db.get_session_by_id(session_id)
        
        return jsonify({
            'success': True,
            'session': session
        })
        
    except Exception as e:
        logger.error(f"åˆ›å»ºä¼šè¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/sessions/<session_id>', methods=['GET'])
def get_session_messages(session_id):
    """è·å–ä¼šè¯çš„æ¶ˆæ¯å†å²"""
    try:
        session = chat_db.get_session_by_id(session_id)
        if not session:
            return jsonify({
                'success': False,
                'error': 'ä¼šè¯ä¸å­˜åœ¨'
            }), 404
        
        page = int(request.args.get('page', 1))
        limit = int(request.args.get('limit', 50))
        offset = (page - 1) * limit
        
        messages = chat_db.get_messages(session_id, limit=limit, offset=offset)
        
        return jsonify({
            'success': True,
            'session': session,
            'messages': messages,
            'pagination': {
                'page': page,
                'limit': limit,
                'has_more': len(messages) == limit
            }
        })
        
    except Exception as e:
        logger.error(f"è·å–ä¼šè¯æ¶ˆæ¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'è·å–ä¼šè¯æ¶ˆæ¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/sessions/<session_id>', methods=['PUT'])
def update_session(session_id):
    """æ›´æ–°ä¼šè¯ä¿¡æ¯"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'
            }), 400
        
        title = data.get('title')
        if title:
            success = chat_db.update_session_title(session_id, title)
            if not success:
                return jsonify({
                    'success': False,
                    'error': 'ä¼šè¯ä¸å­˜åœ¨æˆ–æ›´æ–°å¤±è´¥'
                }), 404
        
        # è·å–æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
        session = chat_db.get_session_by_id(session_id)
        
        return jsonify({
            'success': True,
            'session': session
        })
        
    except Exception as e:
        logger.error(f"æ›´æ–°ä¼šè¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'æ›´æ–°ä¼šè¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/sessions/<session_id>', methods=['DELETE'])
def delete_session(session_id):
    """åˆ é™¤ä¼šè¯"""
    try:
        success = chat_db.delete_session(session_id)
        if not success:
            return jsonify({
                'success': False,
                'error': 'ä¼šè¯ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥'
            }), 404
        
        return jsonify({
            'success': True,
            'message': 'ä¼šè¯å·²åˆ é™¤'
        })
        
    except Exception as e:
        logger.error(f"åˆ é™¤ä¼šè¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/sessions/<session_id>/archive', methods=['POST'])
def archive_session(session_id):
    """å½’æ¡£ä¼šè¯"""
    try:
        success = chat_db.archive_session(session_id)
        if not success:
            return jsonify({
                'success': False,
                'error': 'ä¼šè¯ä¸å­˜åœ¨æˆ–å½’æ¡£å¤±è´¥'
            }), 404
        
        return jsonify({
            'success': True,
            'message': 'ä¼šè¯å·²å½’æ¡£'
        })
        
    except Exception as e:
        logger.error(f"å½’æ¡£ä¼šè¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'å½’æ¡£ä¼šè¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/search', methods=['GET'])
def search_messages():
    """æœç´¢æ¶ˆæ¯"""
    try:
        query = request.args.get('q', '').strip()
        session_id = request.args.get('session_id')
        limit = int(request.args.get('limit', 50))
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º'
            }), 400
        
        search_result = bocha_search_service.search(query, count=limit)
        
        return jsonify({
            'success': True,
            'query': query,
            'results': search_result['results'],
            'images': search_result['images'],
            'total': search_result['total_count'],
            'search_provider': search_result['search_provider']
        })
        
    except Exception as e:
        logger.error(f"æœç´¢æ¶ˆæ¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'æœç´¢å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'success': True,
        'status': 'healthy',
        'message': 'å¤šæ¨¡æ€èŠå¤©æœºå™¨äººæœåŠ¡æ­£å¸¸è¿è¡Œ',
        'capabilities': {
            'siliconflow_available': bool(SILICONFLOW_API_KEY),
            'groq_available': bool(GROQ_API_KEY),
            'openai_available': bool(OPENAI_API_KEY),
            'multimodal_support': bool(GROQ_API_KEY),
            'speech_to_text': True,  # æ”¯æŒæµè§ˆå™¨è¯­éŸ³è¯†åˆ« + OpenAI Whisperå¤‡é€‰
            'browser_speech_recognition': True,  # æµè§ˆå™¨å†…ç½®è¯­éŸ³è¯†åˆ«
            'server_speech_to_text': bool(OPENAI_API_KEY),  # æœåŠ¡ç«¯è¯­éŸ³è½¬æ–‡å­—
            'history_storage': True
        }
    })

@app.route('/api/search/web', methods=['POST'])
def web_search():
    """è”ç½‘æœç´¢API"""
    try:
        # æ£€æŸ¥è¯·æ±‚æ˜¯å¦åŒ…å«JSONæ•°æ®
        if not request.is_json:
            return jsonify({'success': False, 'error': 'è¯·æ±‚å¿…é¡»åŒ…å«JSONæ•°æ®'}), 400
            
        data = request.get_json()
        if data is None:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„JSONæ•°æ®'}), 400
        
        query = data.get('query')
        if not query or not query.strip():
            return jsonify({'success': False, 'error': 'æœç´¢æŸ¥è¯¢ä¸èƒ½ä¸ºç©º'}), 400
        
        # è·å–æœç´¢å‚æ•°
        count = data.get('count', 5)
        freshness = data.get('freshness', 'noLimit')
        include_images = data.get('include_images', True)
        format_for_ai = data.get('format_for_ai', False)
        
        # æ‰§è¡Œæœç´¢
        search_result = bocha_search_service.search(
            query=query,
            count=count,
            freshness=freshness,
            include_images=include_images
        )
        
        # å¦‚æœéœ€è¦æ ¼å¼åŒ–ä¸ºAIå¯è¯»æ–‡æœ¬
        if format_for_ai and search_result.get('success'):
            formatted_text = bocha_search_service.format_search_results_for_ai(search_result)
            search_result['formatted_text'] = formatted_text
        
        return jsonify(search_result)
        
    except Exception as e:
        logger.error(f"è”ç½‘æœç´¢é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'æœç´¢å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/chat/search', methods=['POST'])
def chat_with_search():
    """å¸¦è”ç½‘æœç´¢çš„æ™ºèƒ½å¯¹è¯API"""
    try:
        # æ£€æŸ¥è¯·æ±‚æ˜¯å¦åŒ…å«JSONæ•°æ®
        if not request.is_json:
            return jsonify({'success': False, 'error': 'è¯·æ±‚å¿…é¡»åŒ…å«JSONæ•°æ®'}), 400
            
        data = request.get_json()
        if data is None:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„JSONæ•°æ®'}), 400
        
        user_message = data.get('message')
        if not user_message or not user_message.strip():
            return jsonify({'success': False, 'error': 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        session_id = data.get('session_id', 'default')
        model = data.get('model', 'deepseek-ai/DeepSeek-V2.5')
        search_query = data.get('search_query', user_message)
        auto_search = data.get('auto_search', True)
        
        search_info = ""
        search_results = None
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨æœç´¢ï¼Œå…ˆè¿›è¡Œè”ç½‘æœç´¢
        if auto_search:
            logger.info(f"æ‰§è¡Œè‡ªåŠ¨è”ç½‘æœç´¢: {search_query}")
            # å¢åŠ æœç´¢ç»“æœæ•°é‡ï¼Œæé«˜æœç´¢è´¨é‡
            search_results = bocha_search_service.search(
                query=search_query, 
                count=8,  # å¢åŠ æœç´¢ç»“æœæ•°é‡
                freshness="oneWeek",  # è·å–æ›´æ–°çš„ä¿¡æ¯
                include_images=False,  # ä¸“æ³¨äºæ–‡æœ¬å†…å®¹
                summary=True
            )
            
            if search_results.get('success'):
                search_info = bocha_search_service.format_search_results_for_ai(search_results, max_results=6)
                # æ„å»ºå¼ºåˆ¶ä½¿ç”¨æœç´¢ç»“æœçš„æ¶ˆæ¯
                enhanced_message = f"""ç”¨æˆ·é—®é¢˜ï¼š{user_message}

ã€é‡è¦æç¤ºã€‘ï¼šä»¥ä¸‹æ˜¯ä¸ºå›ç­”ç”¨æˆ·é—®é¢˜è€Œè·å–çš„å®æ—¶æœç´¢ç»“æœï¼Œä½ å¿…é¡»åŸºäºè¿™äº›æœç´¢ç»“æœæ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦ç»™å‡ºé€šç”¨å›ç­”ã€‚

{search_info}

è¯·æ ¹æ®ä»¥ä¸Šæœç´¢ç»“æœï¼Œä¸ºç”¨æˆ·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ã€‚å¦‚æœæ¶‰åŠä»·æ ¼ä¿¡æ¯ï¼Œè¯·æ•´ç†æˆè¡¨æ ¼æ ¼å¼ã€‚"""
            else:
                enhanced_message = user_message
                logger.warning(f"è”ç½‘æœç´¢å¤±è´¥: {search_results.get('error')}")
        else:
            enhanced_message = user_message
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {
                'role': 'system',
                'content': f"""You are an intelligent assistant that combines web search results with elegant presentation. Your responses should be informative, well-structured, and visually appealing like ChatGPT.

ğŸ¯ CORE PRINCIPLES:
1. **Use search results as primary source**: Extract information from provided search data
2. **Structure like ChatGPT**: Use clear headings, tables, lists, and professional formatting
3. **Be comprehensive yet accessible**: Explain complex concepts clearly
4. **Include visual elements**: Use emojis, tables, and markdown formatting

ğŸ“ RESPONSE FORMAT REQUIREMENTS:

For **mathematical concepts** (like Taylor series, calculus, etc.):
```markdown
## ğŸ“š æ¦‚å¿µå®šä¹‰
[Clear, concise definition]

## ğŸ”¢ æ•°å­¦è¡¨è¾¾

$$
[Write complete LaTeX formula here - NO placeholders]
$$

å…¶ä¸­ï¼š
- \\( actual_symbol \\) è¡¨ç¤ºå…·ä½“å«ä¹‰
- \\( actual_symbol \\) è¡¨ç¤ºå…·ä½“å«ä¹‰

## ğŸ’¡ ç›´è§‚ç†è§£
[Intuitive explanation with analogies]

## ğŸ“– ç»å…¸ä¾‹å­
| å‡½æ•° | å±•å¼€å¼ | æ”¶æ•›èŒƒå›´ | åº”ç”¨ |
|------|--------|----------|------|
| \\( e^x \\) | \\( 1 + x + \\frac{{x^2}}{{2!}} + \\frac{{x^3}}{{3!}} + \\cdots \\) | æ‰€æœ‰å®æ•° | æŒ‡æ•°å¢é•¿ |
| \\( \\sin x \\) | \\( x - \\frac{{x^3}}{{3!}} + \\frac{{x^5}}{{5!}} - \\cdots \\) | æ‰€æœ‰å®æ•° | æŒ¯è¡åˆ†æ |

## ğŸš€ å®é™…åº”ç”¨
- **é¢†åŸŸ1**: å…·ä½“åº”ç”¨
- **é¢†åŸŸ2**: å…·ä½“åº”ç”¨

## ğŸ’­ æ·±å…¥æ€è€ƒ
[Thought-provoking insights]

**CRITICAL LATEX REQUIREMENTS**: 
- Use \\( \\) for inline math like \\( f(x) \\), \\( x^2 \\), \\( \\sin(x) \\)
- Use $$ $$ for display math (with line breaks before and after)
- ABSOLUTELY FORBIDDEN: MATH_LATEX_BLOCK_X or MATH_LATEX_INLINE_X or any placeholders
- Write complete LaTeX formulas directly in response
- Example: \\( e^x = 1 + x + \\frac{{x^2}}{{2!}} + \\cdots \\)
- Example display: 

$$
f(x) = \\sum_{{n=0}}^{{\\infty}} \\frac{{f^{{(n)}}(a)}}{{n!}} (x-a)^n
$$
```

For **price/data queries**:
```markdown
## ğŸ“Š [ä¸»é¢˜] ä¿¡æ¯
æ•°æ®æ›´æ–°æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}

| æ¥æº/æœºæ„ | ä»·æ ¼/æ•°æ® | å•ä½ | å˜åŒ– | æ›´æ–°æ—¶é—´ |
|----------|-----------|------|------|----------|
[Extract from search results]

## ğŸ“ˆ å…³é”®å‘ç°
- **ä¸»è¦è¶‹åŠ¿**: ...
- **é‡è¦æ•°æ®**: ...

## ğŸ“š æ•°æ®æ¥æº
[List sources with links]
```

For **general information**:
```markdown
## ğŸ” [ä¸»é¢˜æ¦‚è¿°]
[Brief introduction]

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹
- **è¦ç‚¹1**: è¯¦ç»†è¯´æ˜
- **è¦ç‚¹2**: è¯¦ç»†è¯´æ˜

## ğŸ“Š è¯¦ç»†ä¿¡æ¯
[Use tables, lists, or structured content]

## ğŸ”— å‚è€ƒèµ„æ–™
[Source links from search results]
```

ğŸ¨ FORMATTING RULES:
- Use **bold** for emphasis
- Use \\( \\) for inline math, \\[ \\] for display math
- Use tables for structured data
- Use emojis for section headers (ğŸ“ŠğŸ“šğŸ”ğŸš€ğŸ’¡)
- Include source links in markdown format
- Use proper heading hierarchy (##, ###)

âŒ AVOID:
- Generic responses without using search data
- Poor formatting or plain text responses
- Ignoring the mathematical or technical nature of questions

âœ… ALWAYS:
- Extract specific information from search results
- Present in visually appealing format
- Include proper mathematical notation when relevant
- Cite sources appropriately
- Match the tone and structure of professional AI assistants

Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"""
            },
            {
                'role': 'user',
                'content': enhanced_message
            }
        ]
        
        # è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå›ç­”
        response = chatbot_service.get_response(messages, model=model)
        
        if response['success']:
            # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
            chat_db.add_message(session_id, 'user', user_message)
            chat_db.add_message(session_id, 'assistant', response['response'])
            
            return jsonify({
                'success': True,
                'response': response['response'],
                'model_used': response.get('model_used', model),
                'provider': response.get('provider'),
                'search_performed': auto_search,
                'search_results': search_results,
                'session_id': session_id
            })
        else:
            return jsonify({
                'success': False,
                'error': response.get('error', 'ç”Ÿæˆå›ç­”å¤±è´¥'),
                'search_results': search_results
            }), 500
            
    except Exception as e:
        logger.error(f"è”ç½‘å¯¹è¯é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'å¯¹è¯å¤±è´¥: {str(e)}'
        }), 500

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨èŠå¤©æœºå™¨äºº...")
    print("ğŸ“± è®¿é—®åœ°å€: http://localhost:5000")
    
    try:
        app.run(debug=True, host='0.0.0.0', port=5000)
    except OSError as e:
        if "Address already in use" in str(e):
            print("âŒ ç«¯å£5000å·²è¢«å ç”¨ï¼Œè¯·å…³é—­å ç”¨ç«¯å£çš„ç¨‹åºæˆ–ä½¿ç”¨: lsof -ti:5000 | xargs kill -9")
        else:
            print(f"âŒ å¯åŠ¨å¤±è´¥: {e}") 