#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½æµ‹è¯•æ¨¡å—
æµ‹è¯•APIå“åº”æ—¶é—´ã€å¹¶å‘å¤„ç†èƒ½åŠ›ã€å†…å­˜ä½¿ç”¨ç­‰æ€§èƒ½æŒ‡æ ‡
"""

import pytest
import time
import threading
import requests
import psutil
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.fixture(autouse=True)
    def setup_performance(self):
        """æ€§èƒ½æµ‹è¯•è®¾ç½®"""
        self.base_url = "http://localhost:5000"
        self.session = requests.Session()
        self.process = psutil.Process(os.getpid())
        
        # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
        self.initial_memory = self.process.memory_info().rss
        yield
        
        # æ£€æŸ¥å†…å­˜æ³„æ¼
        final_memory = self.process.memory_info().rss
        memory_increase = final_memory - self.initial_memory
        
        # å¦‚æœå†…å­˜å¢åŠ è¶…è¿‡100MBï¼Œå‘å‡ºè­¦å‘Š
        if memory_increase > 100 * 1024 * 1024:
            print(f"âš ï¸ æ£€æµ‹åˆ°å†…å­˜ä½¿ç”¨å¢åŠ ï¼š{memory_increase / 1024 / 1024:.2f}MB")
    
    @pytest.mark.performance
    def test_api_response_time(self):
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        endpoints = [
            ("/api/health", {}),
            ("/api/models", {}),
        ]
        
        for endpoint, params in endpoints:
            start_time = time.time()
            response = self.session.get(f"{self.base_url}{endpoint}", params=params, timeout=10)
            response_time = time.time() - start_time
            
            assert response.status_code == 200
            assert response_time < 2.0, f"{endpoint} å“åº”æ—¶é—´è¿‡é•¿: {response_time:.2f}s"
            print(f"âœ… {endpoint} å“åº”æ—¶é—´: {response_time:.3f}s")
    
    @pytest.mark.performance
    @pytest.mark.slow
    def test_concurrent_chat_requests(self):
        """æµ‹è¯•å¹¶å‘èŠå¤©è¯·æ±‚"""
        def make_chat_request(request_id: int) -> Dict[str, Any]:
            start_time = time.time()
            try:
                response = self.session.post(
                    f"{self.base_url}/api/chat",
                    json={
                        "messages": [{"role": "user", "text": f"å¹¶å‘æµ‹è¯•è¯·æ±‚ {request_id}"}],
                        "model": "deepseek-ai/DeepSeek-V2.5"
                    },
                    timeout=30
                )
                response_time = time.time() - start_time
                
                return {
                    "request_id": request_id,
                    "status_code": response.status_code,
                    "response_time": response_time,
                    "success": response.status_code == 200,
                    "data": response.json() if response.status_code == 200 else None
                }
            except Exception as e:
                return {
                    "request_id": request_id,
                    "status_code": 500,
                    "response_time": time.time() - start_time,
                    "success": False,
                    "error": str(e)
                }
        
        # å¹¶å‘æ‰§è¡Œ10ä¸ªè¯·æ±‚
        num_requests = 10
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(make_chat_request, i) for i in range(num_requests)]
            results = [future.result() for future in as_completed(futures)]
        
        # åˆ†æç»“æœ
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]
        
        success_rate = len(successful_requests) / len(results)
        avg_response_time = sum(r["response_time"] for r in successful_requests) / len(successful_requests) if successful_requests else 0
        
        print(f"ğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœ:")
        print(f"   - æ€»è¯·æ±‚æ•°: {num_requests}")
        print(f"   - æˆåŠŸè¯·æ±‚: {len(successful_requests)}")
        print(f"   - å¤±è´¥è¯·æ±‚: {len(failed_requests)}")
        print(f"   - æˆåŠŸç‡: {success_rate:.2%}")
        print(f"   - å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        
        # æ–­è¨€ï¼šè‡³å°‘80%çš„è¯·æ±‚åº”è¯¥æˆåŠŸ
        assert success_rate >= 0.8, f"å¹¶å‘æˆåŠŸç‡è¿‡ä½: {success_rate:.2%}"
        
        # æ–­è¨€ï¼šå¹³å‡å“åº”æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        if successful_requests:
            assert avg_response_time < 10.0, f"å¹¶å‘å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}s"
    
    @pytest.mark.performance
    def test_large_payload_handling(self):
        """æµ‹è¯•å¤§è´Ÿè½½å¤„ç†èƒ½åŠ›"""
        # åˆ›å»ºå¤§æ–‡æœ¬æ¶ˆæ¯
        large_text = "è¿™æ˜¯ä¸€ä¸ªé•¿æ–‡æœ¬æµ‹è¯•ã€‚" * 1000  # çº¦10KB
        
        start_time = time.time()
        response = self.session.post(
            f"{self.base_url}/api/chat",
            json={
                "messages": [{"role": "user", "text": large_text}],
                "model": "deepseek-ai/DeepSeek-V2.5"
            },
            timeout=60
        )
        response_time = time.time() - start_time
        
        assert response.status_code == 200
        data = response.json()
        assert data.get("success") is True
        
        print(f"ğŸ“ å¤§è´Ÿè½½æµ‹è¯•ç»“æœ:")
        print(f"   - æ–‡æœ¬å¤§å°: {len(large_text)} å­—ç¬¦")
        print(f"   - å“åº”æ—¶é—´: {response_time:.3f}s")
        
        # å“åº”æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        assert response_time < 30.0, f"å¤§è´Ÿè½½å¤„ç†æ—¶é—´è¿‡é•¿: {response_time:.2f}s"
    
    @pytest.mark.performance
    def test_memory_usage_monitoring(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§"""
        initial_memory = self.process.memory_info().rss
        
        # æ‰§è¡Œå¤šæ¬¡APIè°ƒç”¨
        for i in range(20):
            response = self.session.post(
                f"{self.base_url}/api/chat",
                json={
                    "messages": [{"role": "user", "text": f"å†…å­˜æµ‹è¯•æ¶ˆæ¯ {i}"}],
                    "model": "deepseek-ai/DeepSeek-V2.5"
                },
                timeout=30
            )
            assert response.status_code == 200
        
        final_memory = self.process.memory_info().rss
        memory_increase = final_memory - initial_memory
        
        print(f"ğŸ§  å†…å­˜ä½¿ç”¨æƒ…å†µ:")
        print(f"   - åˆå§‹å†…å­˜: {initial_memory / 1024 / 1024:.2f}MB")
        print(f"   - æœ€ç»ˆå†…å­˜: {final_memory / 1024 / 1024:.2f}MB")
        print(f"   - å†…å­˜å¢é•¿: {memory_increase / 1024 / 1024:.2f}MB")
        
        # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆå°äº50MBï¼‰
        assert memory_increase < 50 * 1024 * 1024, f"å†…å­˜å¢é•¿è¿‡å¤š: {memory_increase / 1024 / 1024:.2f}MB"
    
    @pytest.mark.performance
    @pytest.mark.slow
    def test_session_management_performance(self):
        """æµ‹è¯•ä¼šè¯ç®¡ç†æ€§èƒ½"""
        session_ids = []
        
        # åˆ›å»ºå¤šä¸ªä¼šè¯
        create_start = time.time()
        for i in range(50):
            response = self.session.post(
                f"{self.base_url}/api/sessions",
                json={
                    "title": f"æ€§èƒ½æµ‹è¯•ä¼šè¯ {i}",
                    "model": "deepseek-ai/DeepSeek-V2.5"
                },
                timeout=10
            )
            if response.status_code == 200:
                data = response.json()
                if data.get("success"):
                    session_ids.append(data["session"]["id"])
        
        create_time = time.time() - create_start
        
        # è·å–ä¼šè¯åˆ—è¡¨
        list_start = time.time()
        response = self.session.get(f"{self.base_url}/api/sessions", timeout=10)
        list_time = time.time() - list_start
        
        assert response.status_code == 200
        data = response.json()
        assert data.get("success") is True
        
        # æ¸…ç†åˆ›å»ºçš„ä¼šè¯
        delete_start = time.time()
        for session_id in session_ids:
            self.session.delete(f"{self.base_url}/api/sessions/{session_id}", timeout=10)
        delete_time = time.time() - delete_start
        
        print(f"ğŸ“‚ ä¼šè¯ç®¡ç†æ€§èƒ½:")
        print(f"   - åˆ›å»º50ä¸ªä¼šè¯ç”¨æ—¶: {create_time:.3f}s")
        print(f"   - è·å–ä¼šè¯åˆ—è¡¨ç”¨æ—¶: {list_time:.3f}s")
        print(f"   - åˆ é™¤50ä¸ªä¼šè¯ç”¨æ—¶: {delete_time:.3f}s")
        print(f"   - å¹³å‡åˆ›å»ºæ—¶é—´: {create_time/50:.3f}s/session")
        
        # æ€§èƒ½æ–­è¨€
        assert create_time < 30.0, f"ä¼šè¯åˆ›å»ºæ—¶é—´è¿‡é•¿: {create_time:.2f}s"
        assert list_time < 5.0, f"ä¼šè¯åˆ—è¡¨è·å–æ—¶é—´è¿‡é•¿: {list_time:.2f}s"
    
    @pytest.mark.performance
    def test_api_rate_limiting(self):
        """æµ‹è¯•APIé€Ÿç‡é™åˆ¶å’Œç¨³å®šæ€§"""
        # å¿«é€Ÿå‘é€è¯·æ±‚æµ‹è¯•
        request_times = []
        success_count = 0
        
        for i in range(30):
            start = time.time()
            try:
                response = self.session.get(f"{self.base_url}/api/health", timeout=5)
                request_time = time.time() - start
                request_times.append(request_time)
                
                if response.status_code == 200:
                    success_count += 1
                
            except Exception as e:
                print(f"è¯·æ±‚ {i} å¤±è´¥: {e}")
        
        avg_response_time = sum(request_times) / len(request_times) if request_times else 0
        success_rate = success_count / 30
        
        print(f"âš¡ é€Ÿç‡æµ‹è¯•ç»“æœ:")
        print(f"   - æ€»è¯·æ±‚æ•°: 30")
        print(f"   - æˆåŠŸè¯·æ±‚: {success_count}")
        print(f"   - æˆåŠŸç‡: {success_rate:.2%}")
        print(f"   - å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        
        # æ–­è¨€ï¼šå¤§éƒ¨åˆ†è¯·æ±‚åº”è¯¥æˆåŠŸ
        assert success_rate >= 0.9, f"é«˜é¢‘è¯·æ±‚æˆåŠŸç‡è¿‡ä½: {success_rate:.2%}"


class TestStressTest:
    """å‹åŠ›æµ‹è¯•ç±»"""
    
    @pytest.fixture(autouse=True)
    def setup_stress(self):
        """å‹åŠ›æµ‹è¯•è®¾ç½®"""
        self.base_url = "http://localhost:5000"
        
    @pytest.mark.stress
    @pytest.mark.slow
    def test_sustained_load(self):
        """æµ‹è¯•æŒç»­è´Ÿè½½èƒ½åŠ›"""
        def worker():
            session = requests.Session()
            success_count = 0
            error_count = 0
            
            for i in range(10):
                try:
                    response = session.post(
                        f"{self.base_url}/api/chat",
                        json={
                            "messages": [{"role": "user", "text": f"å‹åŠ›æµ‹è¯• {i}"}],
                            "model": "deepseek-ai/DeepSeek-V2.5"
                        },
                        timeout=30
                    )
                    if response.status_code == 200:
                        success_count += 1
                    else:
                        error_count += 1
                except Exception:
                    error_count += 1
                
                # é—´éš”1ç§’
                time.sleep(1)
            
            return success_count, error_count
        
        # å¯åŠ¨5ä¸ªå¹¶å‘å·¥ä½œçº¿ç¨‹
        threads = []
        for i in range(5):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        print("ğŸ”¥ å‹åŠ›æµ‹è¯•å®Œæˆ")
        # å‹åŠ›æµ‹è¯•ä¸»è¦æ˜¯ä¸ºäº†è§‚å¯Ÿç³»ç»Ÿè¡Œä¸ºï¼Œä¸è®¾ç½®ä¸¥æ ¼çš„æ–­è¨€


if __name__ == '__main__':
    pytest.main([__file__, '-v', '--tb=short']) 